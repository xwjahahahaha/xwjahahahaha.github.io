---
title: 《Blockchained_On-Device_Federated_Learning》
tags:
  - block_chain
  - federated_learing
categories:
  - knowledge
  - block_chain
toc: true
declare: true
date: 2021-03-28 15:36:50
---

# 基本信息

《基于区块链技术的跨设备联邦学习》

![k52km4](http://xwjpics.gumptlu.work/qinniu_uPic/k52km4.png)

# 摘要

我们结合区块链技术,这篇文章提出了一个区块链联邦学习(blockchain federated learning, BlockFL)架构，其中交换和验证了本地学习模型的更新。

这使得设备上的机器学习无需任何集中的训练数据或通过使用区块链中的共识机制进行协调。

此外，我们分析了BlockFL的端到端延迟模型，并通过考虑通信、计算和共识延迟来刻画最优的块生成率。

<!-- more -->

# 1.Introduction引入

未来的无线系统可以保证随时随地的低延迟和高可靠性

为此，设备上的机器学习是一个引人注目的解决方案，其中每个设备存储一个高质量的机器学习模型，从而能够做出决策, 即使它失去了连通性。

训练这样一个设备上的机器学习模型需要比每个设备的本地样本更多的数据样本，并且有必要与其他设备交换样本

在这篇文章中，我们解决了通过与其他设备联合来训练每个设备的本地模型的问题

一个关键的挑战是每个设备都拥有本地数据样本。因此，交换的过程应该保证来自于其他设备原始数据的私有与隐私.

为此，正如谷歌的联邦学习(FL),被称为`vanilla FL`,每个设备交换它自己本地的模型更新

也就是,学习模型的权值和梯度参数，不能从中得到原始数据

如图1-a所示，`vanilla FL`的交换是通过中央服务器的帮助而实现的，中央服务器聚合并获取所有本地模型更新的总体平均值,产生`global model`的更新。然后，每个设备下载全局模型(`global model`)的更新，并计算它的下一个本地更新，直到全局模型训练完成[5]。由于这些交换，`vanilla FL`的训练完成延迟可能是几十分钟或更多，正如谷歌的键盘应用程序( Google’s keyboard application)[7]所演示的那样.

![2ORl0c](http://xwjpics.gumptlu.work/qinniu_uPic/2ORl0c.png)

---

<font color='green'>下面开始分析谷歌Vanilla的缺点: 两个方面: **1.中心服务器的中心化 2. 缺乏奖励措施**</font>

Vanilla FL操作的局限性是双重的。

首先,它依赖于一个**单一的中央服务器**，这在服务器故障时是脆弱的。那么当global model发生不准确的更新时会导致所有的local model发生错误的更新

其次,他对于本地设备没有给予奖励,拥有更多数据样本的设备对全局训练的贡献更大。如果不提供补偿，这样的设备就不太愿意与拥有少量数据样本的其他设备联合.

----

<font color='green'> 引入本项目的架构: BlockFL</font>

为了解决这些紧迫的问题, 通过利用区块链技术作为中央服务器的替代,我们提出了一个Blockchained FL (BlockFL)架构

区块链网络允许交换设备的本地模型更新，同时验证和提供相应的奖励。

BlockFL克服了单点故障问题，并将其联合范围扩展到公共网络中不值得信任的设备，这得益于本地训练结果的验证过程

此外，通过提供与训练样本大小成比例的奖励，BlockFL促进了更多设备与更多训练样本的联合。

---

如图1-b所示，BlockFL的逻辑结构由设备和矿工组成

矿工在物理上可以是随机选择的设备，也可以是独立的节点，如边缘网络(network edges)(即蜂窝网络中的基站).它们在采矿过程中相对不受能源限制。

BlockFL的操作总结如下:

每个设备计算并上传本地模型更新到区块链网络中的相关miner;

矿工交换并验证所有本地模型更新，然后运行工作证明(PoW) [8];一旦一个矿工完成PoW，它会生成一个块，其中记录了已验证的本地模型更新;

最后，生成的存储聚合本地模型更新的块被添加到区块链，也被称为分布式账本，并被设备下载。每个设备从新的块计算全局模型更新。

---

请注意，BlockFL的全局模型更新是在每个设备本地计算的。矿机或设备的故障不会影响其他设备的全局模型更新。

为了这些好处，与普通的FL相比，blockfl需要考虑由区块链网络引起的额外延迟。

为了解决这个问题，通过考虑通信、计算和PoW延迟，建立了Block FL的端到端延迟模型.

<font color='red'>通过调整块生成率，也就是PoW难度，从而使延迟最小化。    </font>

----

# 2.Architecture And Operation 架构和操作

## FL operation in BlockFL:

FL的相关操作: FL在一套设备下操作:$D = \{1,2,…,N_D\}$其中$|D| = N_D$<font color='green'>(一共有$N_D个设备$)    </font> .第i个设备$D_i$拥有的数据样例表示为$S_i$其中$|S_i| = N_i$,并且只训练其本地的模型.设备$D_i$本地模型的更新将会上传到与其相关联的Miner:$M_j$ (这是从一组Miner中统一随机选择出来的, 即$M= \{1,2,…,N_M\}$ )

我们的分布式模型训练主要以平行的方式关注于解决**回归问题**,考虑到整套设备的数据样本: $S = \bigcup^{N_D}_{i=1}S_i$ <font color='green'>(所有数据样本的并集) </font>其中$|S|= N_S$

第k个数据样本$ s_k \in S$ 即 $s_k = \{x_k,y_k\}$是一个d维的列向量$x_k \in \mathbb{R}^d$ 和一个标量值$y_k \in \mathbb{R}$

<font color='green'> ($\mathbb{R}^d$表示的是一个d维的向量)   </font>

训练的目标是使一个全局权重向量$w \in \mathbb{R}^d$ <font color='green'> (权重其实就是参数向量)   </font>的损失函数$f(w)$最小.取损失函数$f(w)$作为均方误差:

$f(w) = \frac{1}{N_S} \sum^{N_D}_{i=1}\sum_{s_k\in S_i}f_k(w)$ 其中 $f_k(w) = (x_k^Tw-y_k)^2/2$

深度神经网络下的其他损失函数也可以像[10]中那样被整合。

---

为了解决这些问题,按照`vanilla FL`在[4]的设置,设备$D_i$通过[4]中的随机方差约化梯度算法训练本地模型.采用分布式近似牛顿法对所有设备的局部模型更新进行聚合.对于每次训练, 设备$D_i$的本地模型都以$N_i$的次数迭代(Ni是Di样本的总数)

对于第$l$次训练的第t次本地迭代,本地权重$w_i^{(t,l)} \in \mathbb{R}^d$为:
$$
w_i^{(t,l)}=w_i^{(t-1, l)}- \frac{\beta}{N_i}([\nabla f_k(w_i^{(t-1, l)})-\nabla f_k(w^{(l)})]+\nabla f(w^{(l)}))
$$
其中的$\nabla$符号:

> 劈形算符，倒三角算符，是一个符号，形为∇。就是对倒三角后面的量做如下操作：**表示对函数在各个正交方向上求导数以后再分别乘上各个方向上的单位向量。**
>
> 劈形算符在数学中用于指代梯度算符。它也用于指代微分几何中的联络（可以视为更广意义上的梯度算符）。它由哈密尔顿引入。

其中$\beta ( >0)$ 是一个步长, $w^{(l)}$表示在第$l$次训练中的全局权重<font color='green'> (每次训练的均方误差)   </font>, 其中:$\nabla f(w^{(l)}) = \frac{1}{N_S}\sum^{N_D}_{i=1}\sum_{s_k\in S_i}\nabla f_k(w^{(l)})$<font color='#e54d42'>(集合所有设备所有样例的$\nabla f_k( w^{(l)})$)   **[全局聚合函数1]**</font>

让$w_i^{(l)}$代表在第$l$次训练中最后一次本地迭代的本地权重,表示为$w_i^{(l)}=w^{(N_i, l)}$ <font color='green'> (样本总数为Ni,最后一次就是t=Ni)</font> 则有:

<font color='#e54d42'>**[全局聚合函数2]**</font>
$$
w^{(l)} = w^{(l-1)}+ \sum^{N_D}_{i=1}\frac{N_i}{N_S}(w_i^{(l)}-w^{(l-1)})
$$
$N_S$为合并各个设备所有样本的总数

在`vanilla FL   `[4]\[5]中,设备$D_i$上传自己的本地模型更新$(w_i^{(l)}, \{\nabla f_k(w^{(l)})\}_{s_k\in S_i})$给中央服务器,其中模型的更新的大小$\delta_m$同等的给各个设备.全局模型更新$(w^{(l)}, \nabla f(w^{(l)}))$<font color='#e54d42'>(通过上面两个聚合函数)</font>由服务器进行计算. **在BlockFL中，服务器实体被区块链网络取代**，详细描述如下.

---

## Blockchain operation in BlockFL:

在BlockFL中，通过$M$中的miner实现区块生成和它们的验证，miner的功能在于在一个分布式账本(即区块链)与本地模型之间**信任的**交换本地模型的更新,

分类帐中的每个块被分为它的主体body部分和头head部分[8]

在BlockFL中,**区块体**中存储着设备D的本地模型更新数据,即设备$D_i$在第$l$次训练更新的数据: $(w_i^{(l)}, \{\nabla f_k(w^{(l)})_{s_k \in S_i}\})$以及它的本地计算时间$T_{local,i}^{(l)}$(这将会在后续讨论)

区块头部包含了指向前一个块的指针、块生成率λ和PoW的输出值的信息.

每一个区块的大小设置为$h + \delta_m N_D$  其中的$h $和$ \delta_m$分别是区块头和模型更新的大小

**每一个矿工Miner拥有一个与其相关联的设备或者其他Miner的充满了本地模型更新数据的候选区块(未上链区块)**,写入区块数据的过程直到达到区块的最大数据量或者达到等待时间$T_{wait}$

---

然后，根据PoW[8]，miner通过改变其输入即nonce随机生成一个哈希值,直到生成的hash值变得小于目标值(难度)

一旦miner $M_1$成功地找到了哈希值，它的候选块就可以成为区块链中一个新的区块，如图2所示。

![6Lbv5h](http://xwjpics.gumptlu.work/qinniu_uPic/6Lbv5h.png)

区块的生成速度$\lambda$可以被POW的难度控制,即POW的难度越大/区块目标值越小,区块生成速率$\lambda$越小

由于其简单、健壮性，PoW应用于无线系统，如[11]、[12]。BlockFL还可以使用其他共识算法，如权益证明(PoS)或拜占庭容错(BFT)，这可能需要更复杂的操作和初步工作来在矿工之间达成共识。

---

生成的块将传播给所有其他矿工。为此，正如[8]中所做的，所有收到生成区块的矿工都被迫停止他们的Pow工作，并将生成的区块添加到本地区块链中.

<font color='green'>分叉问题 </font>

如图2所示,如果另一个矿工$M_2$在第一个生成的块的传播延迟内成功生成了块，那么一些矿工可能会错误地将第二个生成的块添加到他们本地的账本中，称为分叉。在BlockFL中，分叉使得一些设备将一个不正确的全局模型更新应用到它们的下一个局部模型更新。分叉频率随着区块生成速率λ和块传播延迟的增加而增加，其缓解会带来额外的延迟，具体在第三节中进行阐述.

---

<font color='#39b54a'>系统奖励机制:</font>

区块链网络还为设备的数据样本和矿工的验证过程提供奖励，分为数据奖励data reward和挖掘奖励mining reward.

设备$D_i$的**数据奖励**来自于与其相关联的Miner(或者说由其提供),奖励的数量与提供数据样例的大小$N_i$成比例

当miner $M_j$生成一个区块时，它的**采矿奖励**由区块链网络获得，就像在传统的区块链结构中那样.

挖掘奖励的数量与其所有关联设备的总数据样本大小成正比，即$\sum_{i=1}^{N_{M_j}}N_i$ ,其中的$N_{M_j}$代表矿工$M_j$相关联的设备数量.

值得注意的是，BlockFL可以通过奖励机制进一步改进，**不仅可以考虑数据样本的大小，而且可以考虑数据样本的<font color='#e54d42'>质量(特征对于训练模型准确度的提升程度)</font>，这些都影响了FL**

<font color='#39b54a'>作恶情况分析:</font>

不可信的<u>设备</u>可能会通过任意的本地模型更新来扩充它们的可提供的样本大小.矿工在存储这些样本之前会验证这些本地更新, 其通过比较样本大小$N_i$与其相关联的计算时间$T_{local,i}^{(l)}$ <font color='green'> (样本数量与其对应的计算时间是相关的,所以两者不匹配就会错误)   </font>这在实际中可以由英特尔的软件保护扩展(Intel’s  software  guard  extensions)来保证，允许应用程序在受保护环境中运行，这是区块链技术[13]所使用的

## One-epoch BlockFL operation:

如图二所描绘的那样,设备$D_i$在第 $l$次训练过程中整个BlockFL的七部操作步骤:

![6Lbv5h](http://xwjpics.gumptlu.work/qinniu_uPic/6Lbv5h.png)

1. 本地模型更新

   设备$D_i$根据迭代中的$N_i$计算公式(1):

   $w_i^{(t,l)}=w_i^{(t-1, l)}- \frac{\beta}{N_i}([\nabla f_k(w_i^{(t-1, l)})-\nabla f_k(w^{(l)})]+\nabla f(w^{(l)}))$

2. 本地模型更新数据上传

   设备$D_i$同时随机关联一个矿工$M_i$.如果$M = D$,那么从$M \backslash D_i$ <font color='#39b54a'>(从未被选择的M)</font>中挑选一个$M_i$

   设备上传本地模型更新的数据:$(w_i^{(l)}, \{\nabla f_k(w^{(l)})_{s_k \in S_i}\})$和相应的本地计算时间$T_{local,i}^{(l)}$给相关联的miner

3. 验证

   矿工广播获得的本地模型更新。同时，矿工验证从他们的相关设备或其他矿工接收到的本地模型更新。验证的本地模型更新被记录在矿工的候选块中，直到它达到块的大小$(h + \delta_m N_D)$或者最大等待时间$T_{wait}$

4. <font color='#e54d42'>区块生成</font>

   每个矿机都开始运行PoW，直到它找到nonce或者接收到一个生成的块。

5. <font color='#e54d42'>区块广播</font>

   设$M_{o} \in M$首先找到了nonce.它的候选块作为新块生成并广播给所有矿工

   为了避免分叉，一旦每个miner接收到新块，==**就会发送ACK**==，不管分叉是否发生。如果发生分叉事件，操作将重新启动**第一步**

   生成新块的miner将在等待时间$T_{a,wait}$内等待到系统预定义的最大块ACK确认数量

6. 全局模型下载

   设备$D_i$在其相关联的Miner那里下载最新生成的区块

7. 全局模型更新数据

   设备$D_i$本地计算全局模型更新,根据式(2):$w^{(l)} = w^{(l-1)}+ \sum^{N_D}_{i=1}\frac{N_i}{N_S}(w_i^{(l)}-w^{(l-1)})$.通过在生成的块中聚合的全局权重值更新本地模型

整个这样的过程直到得到满意的差距为止: $|w^{(L)}-w^{(L-1)}| \leq \varepsilon$

集中式FL易受服务器故障的影响，服务器故障会扭曲所有设备的全局模型。然而，在BlockFL中，全局模型更新是在每个设备上本地计算的，这对故障是健壮的，并防止矿工的过度计算开销。

# 3.End-to-End Latency Analysis端到端延迟分析

> Throughput，中文译作吞吐量。Latency，中文译作延迟。它们是衡量软件系统的最常见的两个指标。
>
> 吞吐量一般指相当一段时间内测量出来的系统单位时间处理的任务数或事务数（TPS）。注意“相当一段时间”，不是几秒，而可能是十几分钟、半个小时、一天、几周甚至几月。它的单位一般是TPS、每单位时间写入磁盘的字节数等。
>
> 延迟一般包括单向延迟（One-way Latency）和往返延迟（Round Trip Latency），实际测量时一般取往返延迟。它的单位一般是ms、s、min、h等。

我们研究了最优区块生成率$\lambda^*$最小化学习完成延迟为$T_o$,定义为在一个随机选择的设备$D_o \in D$上经过$L$次训练的总时间

## One-epoch BlockFL latency model:

定义第$l$次延迟为$T_o^{(l)}$,其由计算、通信和区块生成延迟决定.首先, 上述的七个步骤中都会带来计算延迟.

设$δ_d$表示单个数据样本的大小与所有数据样本相同。

……...

# 4.Numerical Results and Discussion数值结果与讨论

![5iSsbN](http://xwjpics.gumptlu.work/qinniu_uPic/5iSsbN.png)

![p4pHI2](http://xwjpics.gumptlu.work/qinniu_uPic/p4pHI2.png)

