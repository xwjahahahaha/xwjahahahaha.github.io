---
title: 《Advances_and_Open_Problems_in_Federated_Learning》
tags:
  - null
categories:
  - knowledge
  - null
toc: true
declare: true
date: 2021-04-07 17:14:30
---

# 一、基本信息

该文章由来自麻省理工、斯坦福、加州大学、南洋理工、谷歌等25所国际知名高校(机构)的58位学者联合发表，文章源于2019年6月17日至18日在谷歌西雅图举办的联邦学习学习和分析研讨会，共105页，调研了438篇文献，介绍了最新的联邦学习进展，并提出大量开放型问题。

> 中文翻译版本gitbook: https://xwzheng.gitbook.io/fl/
>
> github地址: https://github.com/open-intelligence/federated-learning-chinese
>
> 原文地址: https://arxiv.org/pdf/1912.04977.pdf

<font color='#39b54a'>感谢翻译,阅读中文版本做了总体的思维导图,以及记录一下文中的细节</font>

<!-- more -->

# 二、总览

# 三、细节记录

## 3.1 基本概念/术语

### 1.IID独立同分布

> 来源:https://blog.csdn.net/weixin_41847115/article/details/82956256

* 独立同分布independent and identically distributed (i.i.d.)

     在概率统计理论中，如果变量序列或者其他随机变量有相同的概率分布，并且互相独立，那么这些随机变量是独立同分布。

     在西瓜书中解释是：输入空间中的所有样本服从一个隐含未知的分布，训练数据所有样本都是独立地从这个分布上采样而得。

* 简单解释:独立、同分布、独立同分布

  * 独立：**每次抽样之间没有关系，不会相互影响**

    举例：给一个骰子，每次抛骰子抛到几就是几，这是独立；如果我要抛骰子两次之和大于8，那么第一次和第二次抛就不独立，因为第二次抛的结果和第一次相关。

  * 同分布：**每次抽样，样本服从同一个分布**

    举例：给一个骰子，每次抛骰子得到任意点数的概率都是六分之一，这个就是同分布

  * 独立同分布：**i,i,d，每次抽样之间独立而且同分布**

* 机器学习领域的重要假设

  IID独立同分布。即假设训练数据和测试数据是满足相同分布的，它是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障(**让机器学习满足概率论上的一些基础假设**)。

* 目前

  机器学习并不总要求独立同分布，在不少问题中要求样本数据采样自同一个分布是因为希望用训练数据集得到的模型可以合理的用于测试数据集，使用独立同分布假设能够解释得通。

  目前一些机器学习内容已经不再囿于独立同分布假设下，一些问题会假设样本没有同分布。

* Non-IID

  不服从独立同分布,**非独立**或者**非同步**或者**两者都不满足**

### 2.超参数

在机器学习的[上下文](https://baike.baidu.com/item/上下文/2884376)中，超参数是在**开始学习过程之前设置值的参数**，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。

### 3.联邦学习概念

#### 1.广泛定义

> 定义: 联合学习是一种机器学习设置，其中**多个实体（客户端）**在**中央服务器或服务提供商**的协调下协作解决机器学习问题。**==每个客户的原始数据都存储在本地，并且不会交换或转移==**；从而代替了用于立即聚合的有针对性的更新用于实现学习目标

自从最初引入联邦学习一词以来，它就着重于移动和边缘设备应用程序[289、287]

#### 2.生命周期

图1 : 联邦学习系统中经过FL训练的模型和各种参与者的生命周期

![mSJGY5](http://xwjpics.gumptlu.work/qinniu_uPic/mSJGY5.png)



典型的工作流程是：

1. **问题识别：** 模型工程师识别确立一个需要在FL中解决的问题。
2. **客户工具：** 如果需要，可以对客户端（例如，在手机上运行的应用程序）进行工具化，以在本地（时间和数量上受限制）存储必要的训练数据。在许多情况下，该应用程序已经存储了这些数据（例如，短信应用程序必须存储文本消息，照片管理应用程序已经存储了照片）。但是，在某些情况下，可能需要维护其他数据或元数据，例如用户交互数据，为监督学习任务提供标签。
3. **仿真原型（可选）：**模型工程师可以使用代理数据集在FL模拟中对模型体系结构进行原型设计并测试学习**超参数。**
4. **联邦模型训练：** 开始执行多个联邦训练任务以训练模型的不同变体，或使用不同的优化超参数。
5. **（联邦）模型评估：** 在对任务进行了足够的训练之后（通常是几天，请参阅下文），将对模型进行分析并选择好的候选。分析可能包括在数据中心的标准数据集上计算的度量矩阵，或者是联邦评估，其中，将模型推送给受约束的客户，以评估本地客户数据。
6. **部署方式：** 最后，一旦选择了一个好的模型，就会通过标准的模型启动过程，包括手动的质量审查，实时A / B测试（通常通过在某些设备上使用新模型以及在其他设备上使用上一代模型来比较其内在性能）以及在一个分阶段推出（以便在影响太多用户之前可以发现并回退不良行为）。模型的特定启动过程由应用程序的所有者设置，通常与模型的训练方式无关。换句话说，此步骤将同样适用于通过联邦学习或传统数据中心方法训练的模型。

----

服务器（服务提供商）通过重复以下步骤直到停止训练来**协调训练过程**（由监视培训过程的模型工程师自行决定）：

1. **客户端选择：**服务器从一组符合资格要求的客户端中采样。例如，为避免影响设备用户，移动电话可能仅在未计量的wi-fi连接上插入且处于空闲状态时才签入服务器。
2. **传播：** 选定的客户端从服务器下载当前模型权重和训练程序（例如TensorFlow图[6]）。
3. **客户端计算：** 每个选定的设备都通过执行训练程序在本地计算对模型的更新，例如，可以在本地数据上运行SGD（如**联邦平均**）。
4. **聚合：** 服务器收集设备更新的汇总。为了提高效率，一旦有足够数量的设备报告了结果，用户就可以在此处放散手。**==此阶段也是许多其他技术的集成点==**，这些技术将在后面讨论，可能包括：**用于增加隐私的安全聚合，为了通信效率而对聚合进行有损压缩，以及针对差分隐私的噪声添加和更新限幅。**
5. **模型选择：** 服务器根据从参与当前轮次的客户端计算出的聚合更新在本地更新共享模型。

#### 3. 分类

![97IYFO](http://xwjpics.gumptlu.work/qinniu_uPic/97IYFO.png)

![AvHxTA](http://xwjpics.gumptlu.work/qinniu_uPic/AvHxTA.png)

![uRzx3l](http://xwjpics.gumptlu.work/qinniu_uPic/uRzx3l.png)

**==跨设备和跨数据孤岛联邦学习是FL域的两个示例==**，但并不旨在穷举。 FL的主要定义特征以黑体字突出显示，但其他特征对于确定适用的技术也至关重要。

## 3.2 Core assumptions 核心假设

### 1.完全去中心化与点对点的分布式学习

在联邦学习中，中央服务器负责协调训练过程并接收所有客户的贡献。因此，服务器是中央播活跃装置，它也可能表现单点故障。尽管大型公司或组织可以在某些应用场景中扮演这个角色，但是在更多协作学习场景中，可靠，强大的中央服务器可能并不总是可用或理想的[392]。此外，如Lian等人[266]所述，**当客户端数量很大时，服务器甚至可能成为瓶颈**。 (尽管可以通过精心设计的系统来减轻这种情况，例如[74])。

完全分散式学习的关键思想是通过**单个客户端之间的对等通信来代替与服务器的通信**。通信拓扑表示为连接图，其中节点是客户端，边表示两个客户端之间的通信通道。通常将网络图选择为具有最小中最大程度的稀疏图，以便每个节点仅需要向/从少量对等点发送/接收消息。<u>这与服务器-客户端体系结构的星形图相反</u>。**在完全去中心化的算法中，每个客户对应一个回合本地更新并与<u>图中的邻居交换信息</u>（**但是请注意，在这种情况下，轮次的概念甚至不需要，参见[78]中有关时钟模型的讨论）。在机器的背景下，在学习过程中，**==本地更新通常是本地（随机）梯度步骤==**，**==而交流则包括与邻居平均一个本地模型参数。==**请注意，不再像标准联邦学习中那样存在模型的全局状态，而是<u>可以设计该过程，以使所有局部模型收敛到所需的全局解决方案</u>，即**各个模型逐渐达成共识**。尽管多主体优化在控制领域有着悠久的历史，但最近在机器学习中已经考虑了SGD的完全分散化变体和其他优化算法，以提高数据中心的可伸缩性[30]以及设备的分散网络[110]。 392、379、54、243、253、153]。他们还考虑了无向网络图，尽管在[30，200]中也研究了有向网络（编码在现实世界中可能出现的单向通道，例如社交网络或数据市场）的情况。

值得注意的是，即使**在上述分散的环境中，中央机构仍可能负责建立学习任务**。例如，考虑以下问题：<u>谁决定在分散环境中训练什么模型？使用什么算法？什么超参数？当某些东西无法按预期工作时，谁负责调试？回答这些问题仍然需要中央机构中参与客户的一定程度的信任。</u>或者，可以由提出学习任务的客户来决定，也可以通过共识计划来共同做出决定（请参阅第2.1.2节）。

![0PIXgP](http://xwjpics.gumptlu.work/qinniu_uPic/0PIXgP.png)

请注意，与FL一样，分散式学习/完全去中心化学习可以进一步划分为不同的用例，其区别类似于表1中比较跨数据孤岛FL和跨设备FL的区别。

#### 1.1 算法挑战

1. 类似传统中央服务器

   * 网络拓扑和异步问题

     Yu等人 [427]表明，一个人可以达到与可靠网络情况相当的收敛速度。其他开放式研究问题涉及**非IID数据分布，更新频率，有效的通信模式和实际收敛时间**[379].

     大多数优化理论的工作都没有明确考虑**拓扑如何影响运行时间**，即完成每个SGD(随机梯度下降)迭代所需的时间。 Wang等 [401]提出了MATCHA，这是一种基于匹配分解采样的分散的SGD方法，它在保持相同的错误收敛速度的同时，减少了任何给定节点拓扑的每次迭代的通信延迟。关键思想是将图拓扑分解为可并行运行的不相交通信链路组成的匹配，并在每次迭代中仔细选择这些匹配的子集。

   * 本地更新分散式SGD

     与小批量SGD中的使用单个SGD步骤的方案相比，在通信回合之前执行几个本地更新步骤的方案的理论分析更具挑战性。

     在非IID本地数据集的情况下，通常证明依赖单个本地更新步骤的方案可以收敛[243，242]。 Wang和Joshi [399]最近提供了具有几个本地更新步骤的案例的收敛性分析。此外，[401]针对非IID数据情况，但是针对基于上述匹配分解采样的特定方案，提供了收敛分析。

     **==了解非IID数据分布下的收敛性以及如何设计实现最快收敛性的模型平均策略==**仍然是一个悬而未决的问题。

2. 完全去中心化的副作用

   * 个性化和信任机制

     与跨设备FL设置类似，对于单个客户端可用的非IID数据分布下的完全分散方案，一项重要任务是==**设计用于学习个性化模型集合的算法。**==

      [392，54]的工作引入了完全去中心化的算法，以通过在具有相似任务（即相似数据分布）的客户端之间平滑模型参数，从而为每个客户端协作学习个性化模型 ,Zantedeschi等。 [431]进一步学习相似度图和个性化模型。在分散式环境中，关键的独特挑战之一仍然是这种方案对恶意行为者的鲁棒性或对不可靠数据或标签的贡献。

     **==激励或机制设计与分散学习相结合的使用是一个新兴且重要的目标，==**如果没有受信任的中央服务器，在环境中可能很难实现。

   * 梯度压缩和量化方法

     **==将一些现有的压缩通信方案从集中协调器促进的设置转换为通用和完全去中心化的设置是一个当前活跃的研究方向== [278, 391, 444, 279]。**一个补充的想法是**设计分散的优化算法**，该算法自然会导致稀疏更新[431]。

#### 1.2 实际挑战

完全去中心化学习的一个正交问题是如何在实践中实现它。本节概述了基于分布式记账的思想的一系列相关想法。

在联合学习方面，该技术的使用可以通过**==使用智能合约进行模型聚合来实现全球服务器的去中心化==，其中执行智能合约的参与客户端可以是不同的公司或云服务。**

但是，在Ethereum[409]等当今的区块链平台上，**默认情况下可以公开获取区块链上的数据**，这可能会阻止用户参与去中心化联邦学习协议，因为数据的保护通常是FL的主要动机。为了解决此类问题，可能会**修改现有的隐私保护技术以适应去中心化联邦学习的情况。**

首先，为了防止参与节点利用单独提交的模型更新，可以使用现有的**==安全聚合协议==**。 **Bonawitz等人提出了一种已在跨设备FL中使用的实用的安全聚集协议。 [73]**，**以协议的复杂性为代价，有效地处理了退出的参与者。**另一种系统是让每个客户在区块链上存入加密货币存款，如果他们在执行过程中退出则受到惩罚。无需处理丢失，可以显着简化安全聚合协议。实现安全聚合的另一种方法是**使用==机密智能合约==**，例如**在安全区域内运行的Oasis协议[104]所启用的合约**。这样，每个客户端都可以简单地提交一个加密的本地模型更新，知道该模型将通过远程证明在安全硬件中解密和聚合（尽管请参阅第4.1节中有关深度隐私的讨论）。

为了防止任何客户端试图通过利用全局模型来重建另一客户端的私有数据，已经针对FL提出了**==客户端级别的差异性隐私[290]==**。**通过在聚合的全局模型上添加足以隐藏任何单个客户端的更新的随机高斯噪声，可以实现客户端级别的差异性隐私。**在分散式联合学习的情况下，我们也可以让每个客户端在本地添加噪音，如[54]中所述。也就是说，每个客户端在局部梯度下降步骤之后在 本地添加一定量的高斯噪声，并将模型提交给区块链。计算本地添加的噪声等级，以便区块链上的聚集噪声能够实现与[290]中相同的客户端级别的差分隐私。最后，可以对区块链上的汇总全局模型进行加密，并且只有参与的客户端才拥有解密密钥，从而保护了模型不受公众攻击。

### 2.跨数据孤岛的联邦学习

如果许多公司或组织共享激励以基于其所有数据来训练模型，但不能直接共享其数据，则跨数据孤岛可能是相关的。这可能是由于机密性的限制或法律的限制，甚至是在一家公司无法将数据集中在不同地理区域之间时，甚至在一家公司内部。这些跨数据孤岛应用引起了广泛的关注。

1. 数据分割

   * 按simple、特征进行分区

      Yang等人也将此差异称为水平和垂直联邦学习。 [419]。

   * 按数据要素划分数据

     Cross-Silo FL采用了非常不同的训练体系结构。它可能包含中央服务器或不包含中央服务器，并且根据训练算法的具体情况，**==客户交换特定的中间结果而不是模型参数==**，以帮助其他方进行梯度计算。参见例如[419，第2.4.2节],在此设置中，应用**安全多方计算**或**同态加密等技术**被提出，这是为了限制其他参与者从培训过程中可以推断出的信息量。这种方法的缺点是训练算法通常取决于所追求的机器学习目标的类型。当前提出的算法包括树[103]，线性和逻辑回归[419、198]和神经网络[276]。

   * 联邦迁移学习

     联邦迁移学习[419]是另一个具有挑战性的概念，其中数据各方仅在用户空间或特征空间中共享部分重叠，并利用现有的迁移学习技术[314]来协作构建模型。现有的公式仅限于2个客户的情况。

2. 激励机制

   除了为FL开发新的算法技术之外，诚实参与的激励机制设计也是一个重要的实践研究问题。这种需求可能会出现在跨设备设置中（例如[225，224]），但在跨孤岛设置中尤其重要，因为<u>参与者也可能是企业竞争对手</u>。相关目标包括==**如何将联邦学习模型产生的收益分配给贡献数据的所有者，以维持长期参与**==，以及**==如何将激励措施与防御对抗性数据所有者的决策联系起来，以增强系统安全性，优化参与者的参与度。数据所有者，以提高系统效率。==**

3. 差异隐私

   有关参与者和威胁模型的讨论也与跨孤岛FL密切相关。但是，**==防范不同行为者可能具有不同的优先级==**。例如，在许多实际情况下，最终的训练模型将仅发布给参加训练的人员，这使得对“世界其他地区”的担忧变得不那么重要了。

   另一方面，对于具有说服力的主张，我们通常需要**==本地差异隐私==的概念**，因为**来自其他客户的潜在威胁可能更加重要**。在客户端不被视为重大威胁的情况下，每个客户端都可以控制来自其各自用户的数据，因此**可能需要在此类用户级别上提供正式的隐私保证**。根据应用，其他目标可能值得追求。但该领域尚未得到系统地探索。

4. 张量分解

   一些工作还研究了跨孤岛联合张量分解，其中多个站点（每个站点都有一组具有相同特征的数据，即水平分区）通过仅与协调服务器共享中间因子同时保持数据私密性来共同执行张量分解。每个站点。在现有工作中，**[236]使用了基于乘数的交替方向方法（ADMM）**，**[280]通过弹性平均SGD（EASGD）算法提高了效率**，并进一步确保了中间因素的差分隐私。

### 3.拆分学习

与之前的着重于数据分区和通信模式的设置相比，拆分学习[190，393] 背后的关键思想是**==在客户端和服务器之间按层划分模型的执行==**（请参照拆分学习项目网站-https://splitlearning.github.io/）。对于训练和推理都可以做到这一点。

在拆分学习的最简单配置中，每个客户端都会计算通过深度网络的前向传播，直到到达称为切割层的特定层。剪切层的输出（称为粉碎数据）被发送到另一个实体（服务器或另一个客户端），这将完成其余的计算。这样就完成了一轮向前传播，而无需共享原始数据。然后可以按照类似的方式从最后一层向后传播梯度直到剪切层。剪切层上的渐变（仅这些渐变）被发送回客户端，其余的反向传播完成。这个过程一直持续到收敛为止，而**不必让客户端直接彼此访问原始数据**。此设置如图2（a）所示，该设置的一种变体如图2（b）所示，其中标签也没有与原始数据一起共享。

![4sfHE2](http://xwjpics.gumptlu.work/qinniu_uPic/4sfHE2.png)

在原始设置中，不会显示原始数据的拆分学习配置，在U形拆分学习设置中，原始数据和标签不会在客户端和服务器实体之间传输。

在[360]中比较了拆分学习和联邦学习的总体交流需求。拆分学习在训练中带来了并行性的另一个方面，**即模型各部分之间的并行化**。客户端和服务器。在[213，207]中，作者打破了部分网络之间的依赖关系，并通过并行化不同部分中的计算来减少总的集中训练时间，这一点在这里也可能是相关的。然而，在边缘设备上探索拆分学习的这种并行化仍然是一个悬而未决的问题。拆分学习还可以将客户端模型组件与最佳服务器端模型组件进行匹配，以自动进行模型选择，如ExpertMatcher [353]所示。

但是，所传达的值通常可以揭示有关基础数据的信息。多少以及是否可以接受，将取决于应用程序和配置。拆分学习的一种变体称为NoPeek SplitNN [395]，它通过减少与原始数据之间的距离相关性[394，378]，从而通过通信活动减少了潜在的泄漏，同时通过分类交叉熵保持了良好的模型性能。关键思想是最小化原始数据点和通信的粉碎数据之间的距离相关性。如果不使用NoPeek SplitNN，则所传达的对象可能包含与输入数据高度相关的信息，这个用途耶可以根据给定的解相关性相对较早地进行拆分。第4节中的许多讨论在这里也很重要，并且提供**专门针对拆分学习的正式隐私保证的分析仍然是一个开放问题。**

## 3.3 efficiency and effectiveness

探索更好的优化算法；提供不同的模型给不同的客户端；让机器学习任务更好，例如：参数搜索、结构搜索和调试在联邦学习场景中更加容易；提高通信效率等等。

解决这些目标的一个**基本挑战就是non-IID(非独立同分布)数据的存**在，因此，我们首先分析这个问题，并强调潜在的解决方案。

### 1.联邦学习中的Non-IID数据

最常见的独立但是非同分布的来源是每个客户端对应着一类特定的用户，一片地理区域，或者一段特定的时间。提出的分类法与数据漂移的概念有密切的关系[304, 327]，它研究训练集分布和测试集分布之间的差异。这里，我们仅考虑每个客户端上数据分布的差异。

对于以下内容，我们假设一个监督任务有特征$x$和其对应的标签$y$。**联邦学习的统计模型涉及到两个层面的采样： 第一层是对客户端$i \sim Q$进行采样（在可用客户端上的数据分布），第二层是对客户端本地数据分布进行采样$(x,y) \sim \mathcal{P}_i(x,y)$。**

**==当在联邦学习中提到数据non-IID时，我们通常指的是客户端$i$和客户端$j$所对应的$\mathcal{P}_i$与$\mathcal{P}_j$不同。==**然而，有一点需要我们特别注意的是：**$\mathcal{Q}$和$\mathcal{P_i}$是可能随着时间的推移而改变，**从而导致另一维度上的non-IID。

为了完整起见，我们注意到，即使对于单个设备上的数据，如果数据没有经过充分的随机打乱顺序，比如：按照时间排列，那么本地数据的独立性也无法保证。一个简单的例子：视频中连续的帧是高度相关的。**客户端内部相关性的来源通常可以通过在本地随机打乱顺序来解决。**

==**非同分布的客户端分布**== 根据Hsieh et al.[205]，我们首先研究了数据偏离同分布的一些常见方式，即对于不用的客户端$i$和客户端$j$的分布不同$P_i \not= P_j$。我们将$P_i(x,y)$重写为$P_i(y|x)P_i(x)$和$P_i(x|y)P_i(y)$让我们能够更加准确地描述他们的区别。

- ***特征分布倾斜（协变量飘移）***：即使共享$\mathcal{P}(y|x)$，不同客户端上的边缘分布$\mathcal{P}_i(x)$也可能不同$^4$。比如，在手写识别领域，用户在书写同一个单词时也可能有着不同的笔画宽度、斜度等。
- ***标签分布倾斜（先验概率飘移）***：即使$\mathcal{P}(x|y)$是相同的，对于不同客户端上的边缘分布$\mathcal{P}_i(y)$也可能不同。比如，当客户端与特定的地理区域绑定时，标签的分布在不同的客户端上是不同的。比如：袋鼠只在澳大利亚或动物园里；一个人的脸只在出现在全球的几个地方；对于手机设备的键盘，某些特定人群使用某些表情，而其他人不使用。
- ***标签相同，特征不同（概念飘移）***：即使共享$\mathcal{P}(y)$，不同客户端上的条件分布$P_i(x|y)$也可能是不同。由于文化差异，天气影响，生活水平等因素，对于相同的标签$y$，对于不同的客户端可能对应着差异非常大的特征$x$。比如：世界各地的家庭图片千差万别，衣着也千差万别。即使在美国，冬季停放的被大雪覆盖汽车的图像只会出现在某些地区。同样的品牌在不同的时间和不同的时间尺度上看起来也会有很大的不同：白天和晚上、季节效应、自然灾害、时尚设计潮流等等。
- ***特征相同，标签不同（概念飘移）***：即使$\mathcal{P}(X)$是相同的，对于不同客户端上的条件分布$P_i(y |x)$也可能不同。由于个人偏好，训练数据项中的相同特征向量可能具有不同的标签。例如，反映情绪或单词联想的标签有着个人和地区差异。
- ***数量倾斜或者不平衡***：不同的客户可以拥有着样本数量差异很大的数据。

> <font color='#39b54a'>需要融合数据,一般要考虑怎样处理非独立同分布问题,例如,不同的地区同样的特征下但是最后的结果标签却不同,原因在于地理环境的差异.</font>#

在现实世界中，联邦数据集**可能同时包含多个上述影响**，**==同时如何去刻画现实世界中的不同客户端之间的数据集的分布是一个重要的开放性问题。==**大多数关于合成的non-IID数据集的实证工作(例如[289])都集中在**标签分布倾斜上**，在这种情况下，non-IID数据集是通过基于标签划分现有数据集的“平面”而形成的。为了更好地理解真实世界的non-IID数据集的性质，我们允许构建受控的但真实的non-IID数据集，用于测试算法和评估它们对不同程度的客户端异构的恢复力。

此外，对于不同的non-IID分布可能需要制定不同的缓解策略。例如：**在特征分布倾斜的情况下，因为$\mathcal{P}(y|x)$被假设是共同的**，这个问题至少在理论上是很清楚的，训练一个全局模型去学习$\mathcal{P}(y|x)$将是合适的。当同一个特征在不同的客户端上被映射到不同的标签上时，某种形式的个性化（详见3.3）可能对学习真正的标签函数很重要。

==**违反独立性**== 在训练过程中，**只要概率分布$\mathcal{Q}$发生变化，就会其导致违反独立性。**举一个具有代表性的例子：在跨设备联邦学习中，设备通常需要满足特定的要求才能够参与训练（详见1.1.2）。设备通常在本地的夜间时间满足这些要求（当它们大概率在充电、使用免费wi-fi和空闲时），因此**设备可用性可能存在明显的昼夜不同**。更进一步的，因为当地的时间直接对应着经度，因此数据的来源就存在着非常大的地理偏见。Eichner等人[151]描述了这个问题和一些缓解策略，但是仍然有许多问题是待解决的。

==**数据集飘移**== 最后，**我们注意到了分布$\mathcal{Q}$和$\mathcal{P}$对于时间的依赖性可能引入传统意义上的数据集偏移（==训练集和测试集的分布不同==）**。此外，其他的条件可能会使有资格训练联合模型的客户端集合与模型被部署的客户端集合不同。例如，训练比预测可能要求设备拥有更大的内存。这些问题将在第6节被更深入的探讨。采取技术来解决数据集飘移对于联邦学习来说是另一个有趣的开放性问题。

### 2.处理Non-IID数据的策略

联邦学习的最初目标是**在所有客户端数据集的并集上训练单个全局模型，而non-IID的数据则使其变得更加困难。**一个自然的方法就是修改现有的算法（例如：通过不同的参数选取）或者探索一种新的方法更高效地达到这个目标。本节的3.2.2将讨论这方法。

对于某些应用程序，**可能可以增加数据以使不同客户端的数据更加相似**。**一种方法是创建一个可以全局共享的小数据集**。这个数据集可能来自一个公开可用的代表性数据源，一个不涉及隐私敏感的独立于客户数据的数据集，或者可能是**原始数据的蒸馏结果**（参考Wang等人[404]）。

客户目标函数的异构性使得如何构建目标函数的问题变得更加重要——现在已经不清楚平等地对待所有的样本是否是有意义的。替代方案包括：**限制任何一个用户的数据贡献**（这对隐私也很重要，见第4节），并在客户端之间引入其他公平概念；参见第6节中的讨论。

但是，如果我们能够**在每个设备上的本地数据上运行训练**（这对于全局模型的联合学习是必要的），那么训练单个全局模型是否是正确的目标呢？在许多情况下，**使用单个模型是首选地**，例如：为了向没有数据的客户端提供模型，或者在<u>为了在部署之前允许进行人工验证和质量确认</u>。然而，由于本地训练是可能的<u>，因此每个客户都有一个定制的模型是可行的</u>。这种方法可以**把non-IID问题从一个bug变成一个特性**，几乎是字面上的意思，即因为每个客户端都有自己的模型，客户端能够独立地参数化模型，看起来有些病态但却让non-IID变得不那么重要。例如：对每一个$i$，$\mathcal{P}_i(y)$只支持一个标签，那么找到一个高精度的全局模型可能是非常具有挑战性的（特别是当$x$的信息相对不足时），**但是训练一个高精度的局部模型是微不足道的（只需要一个持续的预测）**。这种多模型方法将在第3.3节中深入讨论。除了解决非独立的客户端分布之外，使用多个模型还可以解决由于客户端可用性变化而导致的违背独立性的问题。例如，**Eichner等人[151]的方法运行单个训练，但对不同的迭代进行平均，并基于时区/经度为客户端的<u>推断提供不同的模型</u>。**

> <font color='#39b54a'>每个参与者分别在其本地数据上局部训练模型(多模型)可以将Non-IID问题从一个bug变成一个特性</font>

### 3.联邦学习的优化算法

在典型的联邦学习任务中，目标是**学习单个全局模型**，该模型最小化整个训练数据集上的经验风险函数，**训练集数据为所有客户端数据的并集**。联邦优化算法和标准分布式训练方法之间的主要区别是需要处理表格 1中的特征——对于优化需要特别关注：**non-IID和不平衡的数据、有限的通信带宽、不可靠和有限的可用设备。**

当联邦学习在设备的总数非常庞大时（如：跨移动设备），算法每轮只需要一些客户端参与（客户端采样）。此外，每个设备都可能多次参加训练给定的模型，因此算法应当是不状态依赖的。这就排除了直接应用在数据中心上下文中非常有效的各种方法，例如：ADMM之类的有状态优化算法，以及根据前几轮遗留的压缩错误修正更新的有状态压缩策略。

联邦学习算法的在现实中另一个重要考虑是**与其他技术的可组合性**。优化算法并非在生产部署中独立运行，而是需要与其他技术结合使用，如：**第4.2.1节中的加密聚合协议、第4.2.2节的差分隐私(DP)和3.5节中的模型和更新压缩。**如第1.1.2节所述，这些技术中有许多可以应用于基本类型，如“对选定的客户机求和”和“向选定的客户机广播”，以这些基本形式表达的优化算法提供了一个有价值的关注点分割，但也可能排除某些技术，例如：通过异步更新。

联邦学习最常用的优化方法之一是==**联邦平均算法[289]**==，它适用于**本地更新或并行的SGD**。在这里，每个客户机在本地运行一些SGD步骤，然后对更新后的本地模型求平均值，以在协同服务器上形成更新的全局模型。伪代码在算法1中给出(下方)。

![KhyCKS](http://xwjpics.gumptlu.work/qinniu_uPic/KhyCKS.jpg)

**==执行本地更新并减少与中央服务器的通信频率==，解决了在面对数据位置限制和移动设备客户机有限通信能力情况下的核心挑战**。然而，从优化理论的角度来看，这类算法也带来了一些新的算法挑战。在第3.2节中，我们分别讨论了数据跨客户端分布IID和non-IID情况下，联邦优化算法的最新进展和面临的挑战。开发专门针对联邦学习场景特征的新算法仍然是一个重要的开放问题。

#### 1.优化算法和IID数据集的收敛率

….

联邦平均法（又称并行SGD/本地SGD）自然地需要和两个基准线进行对比：首先，我们可以在每一轮本地更新中固定$x$，并计算当前$x$总的$KM$梯度，以加速的mini-batch数据SGD的运行。令$\bar{x}$表示该算法$T$次迭代的平均值。对于凸问题[256, 119, 132]，我们可以得到上界：

比较这两个结果，我们可以看到mini-batch数据SGD达到了最佳的“统计”项$(\sigma / \sqrt{T K M})$，而对于单客户端SGD（忽略其他设备的更更新）获得了最佳的“优化”项$(H/ \sqrt{(HK)^2})$。

….

联邦学习中的另一个重要设计参数是**==模型聚合方法==**，**该方法用于使用选定客户端进行的更新来更新全局模型**。在最初的联邦学习论文中，**McMahan等人[289]建议对本地模型进行加权平均，与本地数据集的大小成比例**。对于IID数据，假定每个客户端都有一个无限大的数据集，这可以简化为对本地模型进行简单的平均。但是，尚不清楚此聚合方法是否为最快的错误收敛方法。

….

所有$M$个客户端执行相同数量的本地更新的本地更新SGD方法可能会遇到一个常见的**可伸缩性问题**，即**==如果任何一个客户端意外地速度慢或失败，则它们就可能会成为瓶颈==**。可以使用多种方法来解决此问题，但尚不清楚哪种方法是最佳的，尤其是在考虑到潜在的偏差时（请参见第6节）。Bonawitz等[74]建议为客户提供过多的资源（例如，向130万个客户请求更新），然后接受收到的前$M$个更新，并拒绝后续掉队者的消息。稍微复杂一点的解决方案是固定一个时间窗口，并允许客户端在此期间尽可能多地进行本地更新$K_i$轮，然后由中央服务器平均其模型。解决客户端掉队者问题的另一种方法是在$\tau$处固定本地更新的数量，但允许客户端以同步或无锁方式更新全局模型。尽管一些先前的工作[432，267，143]提出了类似的方法，但是误差收敛分析是一个开放且具有挑战性的问题。但是，联邦学习环境中的一个更大挑战是，从第3.2节开始讨论起，**异步方法可能会变得难以与差异性隐私或安全聚合之类的互补技术结合起来。**

….

除了本地更新的数量外，每次训练选择的客户群大小的选择与本地更新的数量存在类似的折中点。更新并平均更大数量的客户端可以让每个训练回合的模型产生更好的收敛性，但是由于与客户端进行的计算/通信中的不可预测的尾部延迟，使得训练速度容易受到下降。

#### 2.对于Non-IID数据集的优化算法和收敛速率

相比中心学习中经过充分随机而得到的独立且同分布的（IID）样本，联邦学习的样本使用来自最终用户设备的本地数据，从而产生了多种non-IID数据。

在这种假设下，对于$N$个客户端都拥有自己的本地数据分布$\mathcal{P}_i$和本地目标函数：

![DollzD](http://xwjpics.gumptlu.work/qinniu_uPic/DollzD.png)

其中$f(x;z)$为模型$x$对于样本$z$的损失。我们通常希望最小化：

![ULzigo](http://xwjpics.gumptlu.work/qinniu_uPic/ULzigo.png)

请注意，当$\mathcal{P}_i$是同分布的时候，这就沦落为IID的设定。我们定义$F^*$为$F$的的最小值，此时观测值为$x^*$。类似的，我们使用$f_i^*$代表$f_i$的最小值。

像在IID设定中一样，我们假设采用间歇性通信模型（例如Woodworth等人[411,第4.4节]），其中$M$个无状态客户参与$T$轮更新，并且在每个轮次中，每个客户可以计算$K$个样本（例如 mini-batches）的梯度。不同之处在于，样本$z*{i,1},...,z*{i,K}$由第$i$个客户端的本地数据分布$\mathcal{P}_i$采样而出。与IID设定不同，我们不必假定$M=N$，因为客户端分布并不完全相等。在下文中，如果算法假定$M=N$，我们将忽略$M$并地写作$N$。我们注意到，尽管这样的假设可能与表1中的跨数据孤岛的联邦假设兼容，但在跨设备的假设中通常是不可行的。

尽管[370,428,399,371]主要针对IID假设，但可以通过对数据差异添加假设，例如通过限制客户端梯度与全局梯度[266,261,265,401]之间或客户端之间和全局最优值的差异[264,232]，将分析技巧推广到非IID场景。在这种假设下，Yu等 [429]表明，在non-IID情况下，本地SGD的错误边界变得更糟。为了达到$1/\sqrt{TKN}$的比率（在非凸目标下），本地更新数$K$应该小于$T^{1/3}/N$，而不是像IID情况下的$T/N^3$[399]。Li等[261]提出在每个局部目标函数中添加一个近似项，以使该算法对局部目标之间的异质性更加鲁棒。所提出的FedProx算法从经验上提高了联邦平均的性能。但是，目前尚不清楚是否可以证明提高收敛速度。Khaled等[232]假设所有客户都参与，并在客户上使用批量梯度下降，这可能比客户上的随机梯度更快地收敛。

==**与去中心优化的联系**== 近年来，在去中心优化社区中研究了联邦优化的目标函数。如Wang和Joshi [399]所示，**去中心SGD的收敛分析可以与本地SGD结合使用**，也可以与网络拓扑矩阵（混合矩阵）的设定适当结合使用。为了减少通信开销，**Wang和Joshi [399]提出了周期性去中心SGD（PD-SGD），它允许去中心SGD使用多次本地更新作为联邦平均**。**Li[265]等人将此算法进行了推广到了non-IID情况。 MATCHA [401]通过随机采样客户端进行计算和通信进一步提高了PD-SGD的性能，并提供了一种收敛分析，表明本地更新可以加速收敛。**

**加速和方差减少技术** 对于一阶优化方法，动量和方差减少是改善优化和泛化性能的有效的方法。但是，关于如何将动量或减少方差的技术应用于本地SGD和联邦平均，仍未达成共识。SCAFFOLD [227]用控制变量显式地模拟客户端更新中的差异以执行方差减少，这可以快速收敛而不会限制客户端数据分布的差异。至于动量方案，Yu等[429]建议让每个客户保持一个局部动量缓冲区，并在每个通信回合中平均这些局部缓冲区以及局部模型参数。尽管此方法从经验上提高了本地SGD的最终准确性，但它需要两倍的通信成本。**Wang等[402]提出了另一种称为SlowMo的动量方案，该方案可以显着提高本地SGD的优化和泛化性能，而无需牺牲吞吐量。**Hsu等[206]提出了一种类似于SlowMo的动量方案。 [429,402]均证明了局部SGD的动量变体可以以与同步mini-batch SGD以相同的速率收敛到非凸目标函数的平稳点，但要证明动量能加快联邦假设下的收敛速度是充满挑战性的。

### 4.多任务学习，个性化和元学习

在本节中，我们考虑**==各种“多模型”方法==**——对于不同的客户端在推断的时候可以高效地使用不同的模型。**当面对non-IID数据（第3.1节）时，这些技术尤其重要，因为它们可能优于潜在的全局共享最优模型**。我们注意到，**个性化已经在完全去中心的设定下也得到了一定的研究[392,54,431,22]，在这种情况下，训练个体模型尤为自然。**

#### 1.通过特征个性化

本节的其余部分专门考虑了不同用户在使用不同模型参数（权重）进行运行推断时的技术需求。但是，**在某些应用程序中，只需将用户和上下文功能添加到模型中，即可获得相近的收益。**例如，考虑一下Hard等人[196]中用于移动键盘中下一个单词预测的语言模型。不同的客户端可能使用不同的语言，实际上，模型参数的设备上个性化已为该问题带来了显着改善[403]。但是，**一种更加完善的方法可能是训练一个联邦模型，该模型不仅要输入到目前为止用户输入的单词，还要<u>输入各种其他用户和上下文特征作为输入</u>**，例如：该用户经常使用哪些单词？ 他们当前正在使用什么应用程序？ 如果他们正在聊天，他们之前曾向此人发送过哪些消息？ **适当地加以个性化，这样的输入可以允许共享的全局模型产生更好的个性化预测**。 但是，由于很大程度上很少有公共数据集包含此类辅助功能，因此探索如何有效合并不同任务上下文信息的模型结构仍然是一个重要的开放问题，有可能极大地提高联邦学习训练的模型的实用性。

> <font color='#39b54a'>把因为“环境”作为特征考虑到联邦学习中,以此来来减少Non-IID的影响</font>

#### 2.多任务学习

如果人们将每个客户的本地问题（本地数据集上的学习问题）视为一项单独的任务（而不是单个数据集的一个划分），那么多任务学习[433]的技术将立即变得有意义。值得注意的是，**史密斯等[362]引入了用于多任务联合学习的MOCHA算法，直接解决了通信效率、掉队者和容错的挑战。** **在多任务学习中，训练过程的结果是==每个任务得到一个模型==。** 因此，大多数多任务学习算法都假设所有客户（任务）都参与每个训练周期，并且由于每个客户都在训练一个单独的模型，因此也要求客户有自己的状态。 **这使得此类技术与数据孤岛联邦学习应用相关性更高**，但在跨设备方案中更难应用。

另一种方法是**重新考虑客户（本地数据集）和学习任务（待训练的模型）**之间的关系，对于每个客户端观察单个模型和全局模型的共同点。例如，可能可以应用来自多任务学习的技术（以及其他方法，如个性化，将在接下来进行讨论），其中我们将“任务”作为客户端的子集，也许是显示选择的（例如，基于地理区域与设备或者用户的特征），或者可能基于在客户端上学习到的聚类或学习到的图的连接结构[431]。这些算法的发展是一个重要的开放问题。请参阅第4.4.4节，讨论关于稀疏的联邦学习问题（例如，在这种类型的多任务问题中自然会产生的问题）的解决方式，而不必揭示每个客户端所属的客户端子集（任务）。

#### 3. 本地微调和元学习

本地微调，我们指的是**通过联邦学习训练单个模型，然后将模型部署到所有的客户端中，并在被用于预测前==使用本地的数据集通过额外的训练达到个性化的效果==。**

这种方法自然地融入了联邦学习模型的通常的生命周期（第1.1.1节）。仍然可以在每轮（例如，100秒）中仅使用少量客户样本进行全球模型的培训；部署模型后，仅发生一次向所有客户端（例如数百万个）广播全局模型。**唯一的区别是，在使用模型对客户进行实时预测之前，会进行最终的训练，从而将模型为本地数据集进行个性化。**

给定一个性能优异的全局模型，对其进行个性化设置的最佳方法是什么？在非联邦学习中，研究人员经常使用**微调、迁移学习、域自适应[284,115,56]**或者使用本地个性化的模型进行插值。 当然，例如插值等技术，关键在于联邦学习的背景下保证其相应的学习效果。此外，这些技术通常仅假设一对域（源域和目标域），因此可能会丢失联邦学习的一些较丰富的结构。

另一种研究个性化和非个性化的方法是通过==**元学习**==来进行，这是一种流行的模型适应设定。 在标准的learning-to-learn（LTL）设置中[52]，它对任务上具有一个元分布，用来学习一个学习算法的样本，例如通过发现参数空间的好的约束。 这实际上很好的对应了第3.1节中讨论的统计设定，其中我们对客户端（任务）$i\sim \mathcal{Q}$进行采样，然后从$\mathcal{P_i}$采样该客户端（任务）的数据。

最近，已经开发了一种称为**模型不可知元学习（MAML）的算法，即元学习全局模型，**它可以**仅使用几次局部梯度迭代作为学习适合于给定任务的良好模型的起点**。 最值得注意的是，**流行的Reptile算法[308]的训练阶段与联邦平均[289]密切相关**，即Reptile允许服务器的学习率，并且假设所有客户端都拥有相同数量的数据，但其他都是相同的。Khodaketal等人[234]和Jiang等人[217]探索了FL和MAML之间的联系，并展示了MAML的假设是一个可以被联邦学习用于性化模型的相关框架。其他和差分隐私的关系在[260]中被研究。

将FL和MAML的思想相结合的总体方向是相对较新的，存在许多未解决的问题：

- 监督任务的MAML算法评估主要集中在合成图像分类问题上[252,331]，其中可以通过对图像类别进行下采样来构造无限的人工任务。用于模拟FL实验的现有数据集建模的FL问题（附录A）可以作为MAML算法的现实基准问题。
- 观察到的全局准确性与个性化准确性之间的差距[217]提出了一个很好的论据，即个性化对于FL至关重要。但是，现有的工作都没有清楚地阐明用于衡量个性化表现的综合指标。例如，对于每个客户来说，小的改进是否比对一部分客户的更大改进更好？相关讨论，请参见第6节。
- Jiang等[217]强调了一个事实，即具有相同结构和性能但经过不同训练的模型可以具有非常不同的个性化能力。尤其是，以最大化全局性能为目标去训模型似乎实际上可能会损害模型的后续个性化能力理解这个问题的根本原因和FL社区与更大的ML社区都相关。
- 在此多任务/LTL框架中，已经开始研究包括个性化和隐私在内的几个具有挑战性的FL命题[234,217,260]。是否还可以通过这种方式分析其他例如概念漂移的问题，比如作为终身学习中的问题[359]？
- 非参数传递LTL算法（例如ProtoNets [363]）是否可以用于FL？

#### 4.何时进行全局FL训练更好

**哪些是联邦学习可以为你做，而在一个设备上进行本地学习是做不了的？**当本地数据集很小且数据为IID时，FL显然具有优势，实际上，**联邦学习[420,196,98]的应用实际受益于跨设备训练单个模型**。另一方面，给non-IID的分布的类型（例如，$\mathcal{P}*i{y|x}$跨客户端是完全不同的），则局部模型会更好。因此，一个自然的理论上的问题是**确定在什么条件下共享全局模型比独立每设备模型更好**。假设我们使用每个客户端可用的$m_k$样本为每个客户端$k$训练模型$h_k$。我们能否保证通过联帮学习学习的模型$h*{FL}$在用于客户$k$时至少与$h*k$一样准确？我们能否量化通过联帮学习可以预期获得多少改进？并且我们是否可以在理论上保证至少与两个自然基准（$h_k$和$h*{FL}$）的性能相匹配的情况下制定个性化策略？

其中一些问题与先前在多源域适应和不可知联合学习方面的工作有关[284,285,203,303]。这些问题的难易程度取决于各方之间的数据分配方式。例如，如果数据是垂直切分的，则每一方都维护有关公共实体的不同功能集的私有记录，则这些问题可能需要解决联邦学习任务中的记录链接[108]。独立于私下进行记录链接的最终技术要求[348]，该任务本身在现实世界中恰好有很大的噪声倾向[347]，只有很少的结果讨论了它对训练模型的影响[198]。可以在有监督的学习中使用损失分解技巧来缓解垂直划分假设本身，但实际的好处取决于数据的分布和参与方的数量[320]。

### 5. 使用于联邦学习的ML工作流

在将标准机器学习的工作流和流水线（包括数据扩充、功能工程、神经网络结构设计、模型选择、超参数优化和调试）适应去中心数据集和资源受限的移动设备时，会遇到许多挑战。我们在将下面讨论其中一些挑战。

#### 1.超参数调整

在资源有限的移动设备上**使用不同的超参数进行多轮培训可能会受到限制**。对于小型设备，这可能导致过度使用有限的通信和计算资源。但是，最近的深度神经网络在很大程度上依赖于有关神经网络的结构、正则化和优化的超参数选择。对于大型模型和大规模设备上的数据集，评估可能会很昂贵。….

除了通用方法来解决超参数优化问题外，对于特殊的训练空间去针对性地去发展容易调整的优化算法也是一个主要的开放领域。中心式训练已经需要调整学习率、动量、批量大小和正则化等参数。**联邦学习可能会添加更多的超参数，如：分别调整聚合/全局模型更新规则和本地客户端优化程序、每轮选择的客户端数量、每轮本地步骤的数量、更新压缩算法的配置等等。**除了更高维度的搜索空间之外，<u>联邦学习通常还需要更长的训练时间并受限于有限的计算资源</u>。应该通过对超参数设置具有鲁棒性的优化算法（相同的超参数值适用于许多不同的现实世界数据集和网络结构）以及自适应或自调整[381,75]算法来解决这一挑战。

#### 2.神经结构设计

我们建议研究人员和工程师在联邦学习环境中探索神经体系结构搜索（NAS）。这是由于当前使用预定的深度学习模型的方法的缺陷引起的：当用户生成的数据对模型开发人员不可见时，深度学习模型的预定网络结构可能不是最佳的设计选择。

#### 3.联邦学习的调试和可解释性

尽管联邦模型联邦训练取得了实质性进展，但这完全是ML工作流的一部分。经验丰富的建模人员可以直接检查子数据集的任务，包括基本的健全性检查、调试错误分类\发现异常值\手动标记样本或检测训练集中的偏差。**==开发隐私保护技术来解决此类去中心的问题是主要的开放性问题上==**。最近，Augensteinetal[32]提出了使用经过联帮学习训练的差分生成模型（包括GAN）的使用，以回答此类问题。但是，仍然存在许多悬而未决的问题（请参见[32]中的讨论），特别是改进FL DP生成模型的精确度的算法的开发。

### 6. 通信和压缩

现在，众所周知，**通信可能是联邦学习的主要瓶颈**，因为无线连接和其他最终用户互联网连接的运行速率通常低于数据中心内或数据中心间连接的速率，并且可能昂贵且不可靠。这引起了最近对减少联邦学习的通信带宽的极大兴趣。**[245]联邦平均和模型更新的量化和量化到少量比特的方法已经证明，通信成本显著降低，并且对训练精度的影响最小**。但是，尚不清楚是否可以进一步降低通信成本，以及这些方法中的任何一种或其组合是否可以接近在联邦学习中的通信和准确性之间提供最佳的折衷。描述这种精确性和通信量之间的基本平衡是理论统计学最近的研究热点[434,81,195,11,47,380]。这些工作描述了在通信约束下用于分布式统计估计和学习的最佳最小极大速率。然而，由于**这些理论工作通常忽略了优化算法的影响，因此很难在实践中从这些理论工作中得出具体的结论来减少通信带宽**。利用这种统计方法来指导实际的训练方法仍然是一个开放的方向。

**压缩目标** 由于当前设备中计算机、内存和通信资源的限制，有几个不同的具有实用价值的压缩目标如下:

 (a)==梯度压缩==，减少从客户端到服务器通信的对象的大小，该对象用于更新全局模型；

 (b)==模型广播压缩==，减小从服务器向客户端广播的模型的大小，客户端从该模型开始本地训练；

 (c)==减少本地计算==，修改整体训练算法，使本地训练过程在计算上更加高效。

这些目标在大多数情况下是互补的。其中，**(a)在总运行时间方面具有最大的实际影响潜力**。这是因为客户端连接的上传速度通常比下载速度慢，因此与(b)相比，可以获得更多的带宽，也因为在许多客户端上平均的效果可以实现更积极的有损压缩方案。通常，(c)与(a)和(b)通过特定的方法共同实现。

许多现有的文献适用于目标(a)**[245, 376, 244, 20, 204]**。(b)对一般收敛性的影响直到最近才得到研究，在[231]中有一个有限的分析。Caldas等人[87]提出了一种联合处理所有(a)、(b)和(c)的方法，该方法通过约束所需的模型更新，使得只有模型变量特定的元素需要在客户端被使用。

在跨设备FL中，算法通常不能假设客户端上保留了任何状态(表1)。但是，在跨数据孤岛FL设置中通常不存在这种约束，在跨设备FL设置中，相同的客户端重复参与。因此，一些更广泛的关于错误修正的思想，如[272,346,396,380,228,371]在这种情况下是相关的，其中许多可以同时处理(a)和(b)。

另一个目标是修改训练程序，以使最终模型更紧凑或更有效地进行预测。这个主题在更大的ML社区中得到了很多关注[194,120,436,270,312]，但是这些方法或者没有直接对应到联邦学习，或者使训练过程更加复杂，这使得它变得很难采纳。同时产生一个紧凑的最终模型的研究，也同时解决了上述三个目标，具有产生实际影响的巨大潜力。

对于梯度压缩，依据最小的最大感知量出现了一些现有的工作[376]，以表征最坏的情况。然而，通常在信息论中，压缩保证是特定于实例的，并取决于基础分布的熵[122]。**换句话说，如果数据易于压缩，则可以证明它们被大量压缩**。 有趣的是，是否可以为梯度压缩获得类似的实例特定结果。同样，最近的工作表明，以数据相关的方式学习压缩方案可以显着提高数据压缩[412]和梯度压缩的压缩率。因此，值得在联邦设定中评估这些与数据相关的压缩方案[171]。

**差分隐私和安全聚合的兼容** 联邦学习中使用的许多算法，例如**安全聚合[72]和使噪声变淡以实现差分隐私[7，290]的机制**，都没有设计用于压缩或量化通信。例如，Bonawitz等人的Secure Aggregation协议的直接应用。 [73]要求每个标量有一个额外的$O(logM)$通信位，其中$M$是要累加的客户端数，这可能会使$M$大时更新的主动量化无效（尽管更有效的方法请参见[75]）。现有的噪声添加机制假定在每个客户端上添加实值高斯或拉普拉斯噪声，这与用于减少通信的标准量化方法不兼容。我们注意到，最近的一些工作允许有偏估计，并且可以很好地与Laplacian噪声[371]一起使用，但是无论如何都不会放弃差分隐私，因为它们在两轮之间具有独立性。在增加离散噪声方面有一些工作[13]，但目前还不清楚这些方法是否最佳。 因此，**==联邦设定下具有兼容性和安全性的压缩方法是一个有价值的开放问题。==**

**无线联邦学习协同设计** 联邦学习中的现有文献通常忽略了模型训练期间无线通道动态的影响，这有可能破坏训练周期，从而破坏整个生产系统的可靠性。特别是，无线干扰，嘈杂的信道和信道波动会严重阻碍服务器与客户端之间的信息交换（或直接在单个客户端之间进行信息交换，如在完全分散的情况下，请参阅第2.1节）。对于任务关键应用程序而言，这是一项主要挑战，其根源在于减少延迟和增强可靠性。应对这一挑战的潜在解决方案包括联邦蒸馏（FD），其中工人交换它们的模型输出参数（logit）而不是模型参数（梯度和/或权重），并通过适当的通信和计算资源来优化工人的调度策略[ 215、316、344]。另一种解决方案是利用无线信道的独特特性（例如广播和叠加）作为自然的数据聚合器，其中，不同工作人员同时传输的模拟波会叠加在服务器上，并由无线信道进行系数权衡[8]。这样可以在服务器上更快地进行模型聚合，并且可以将训练速度加速因子提高到参与者的数量。这与传统的正交频分复用（OFDM）范式形成鲜明对比，在传统的正交频分复用（OFDM）范式中，工人在正交频率上上传其模型，而正交频率的性能会随着参与数量的增加而降低。

### 7.应用到更多类型的机器学习问题和模型

迄今为止，**联邦学习主要考虑了监督学习任务**，其中每个客户都自然可以获得标签。 **==将FL扩展到其他ML范式，包括强化学习、半监督和无监督学习、主动学习和在线学习[200，435]都提出了有趣且开放的挑战。==**

与FL高度相关的另一类重要模型是可以**表征预测不确定性的模型**。大多数现代深度学习模型无法表示其不确定性，也无法对参数学习进行概率解释。这推动了贝叶斯模型与深度学习相结合的工具和技术的最新发展。从概率论的角度来看，使用单点估计进行分类是不合理的。贝叶斯神经网络[358]已经被提出并显示出对过度拟合更为健壮，并且可以轻松地从小型数据集中学习。贝叶斯方法通过其参数以概率分布的形式进一步提供不确定性估计，从而防止过度拟合。此外，借助概率推理，人们可以预测不确定性如何减小，从而使网络做出的决策随着数据大小的增长变得更加准确。

由于贝叶斯方法相比深度模型在置信度上拥有丰富的经验，并且在许多任务上也能达到最先进的性能，因此人们**希望贝叶斯方法能够为经典的联邦学习提供理论上的改进。**实际上，**==Lalitha等人的初步工作[254]表明，合并贝叶斯方法可用于跨non-IID数据和异构平台的模型聚合==**。但是，必须解决**有关可伸缩性和计算可行性**的诸多问题。

## 3.4 Privacy 隐私

