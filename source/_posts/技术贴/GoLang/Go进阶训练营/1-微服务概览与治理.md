---
title: 1-微服务概览与治理
tags:
  - golang
categories:
  - technical
  - null
toc: true
declare: true
date: 2021-10-30 13:46:18
---

[TOC]

<!-- more -->

# 一、微服务概览

## 1.1 单体架构

单体式应用，拓展难可靠性低 ，敏捷性开发和部署无法完成

改变思路： 化繁为简，分而治之

## 1.2 微服务起源

### 1. SOA服务与微服务

SOA 面向服务架构的基本概念：

> 面向服务架构（SOA）是一个组件模型，它将应用程序的不同功能单元（称为服务）进行拆分，并通过这些服务之间定义良好的接口和协议联系起来。接口是采用中立的方式进行定义的，它应该独立于实现服务的硬件平台、操作系统和编程语言。这使得构建在各种各样的系统中的服务可以以一种统一和通用的方式进行交互。

简单的理解：SOA就是将把系统按照实际业务，拆分成刚刚好大小的、合适的、独立部署的模块，每个模块之间相互独立。

https://www.zhihu.com/question/42061683

微服务就是SOA的一种实践，微服务起源于SOA，本质上都是面向服务的架构，微服务比SOA拆分更小一点，有更加细致的定义：

* **小即是美**：小的服务代码少、易测试、维护

* **单一职责**：一个服务只需要做好一件事

* **尽可能早的创建原型**：尽早的定义API，建立服务契约，达成服务间沟通的一致性约定，完善的事以后再做

  > <font color='#39b54a'>类似于前后端开发，事先商量好API，然后大家再一起开发</font>

* **可移植性比效率更重要**：服务间的轻量级交互协议在效率与可移植性二者之间，首要考虑兼容性和可移植性

### 2. 微服务定义

围绕业务功能构建，<u>每个服务关注单一的业务</u>，<u>服务间采用轻量级的通信机制</u>，可以<u>全自动独立部署</u>，可以<u>使用不同的编程语言与数据存储技术</u>。微服务架构<u>通过业务拆分实现服务的组件化</u>，通过<u>组件的组合又可以实现快速的开发系统</u>，业务单一的服务组件又可以独立部署。

主要特点如下：

* 原子服务
* 独立进程
* 隔离部署
* 去中心化服务治理

例图，微服务的架构：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20211030143010567.png" alt="image-20211030143010567" style="zoom:50%;" />

### 3. 微服务的缺点

细粒度的划分会使整个系统变得复杂，基础设施要求高、查错排错相对麻烦

* **微服务是分布式系统，会带来分布式固有的复杂性。**进程通讯交互采不得不使用RPC或消息传递；此外还需要写代码处理消息过慢或服务不可用等失效问题
* **分布式数据库架构，同时更新多个业务主体的事务普遍**。相比于单体，微服务需要快速更新多个不同的数据库，分布式一致性如何解决
* **测试困难** 
* **服务间的模块依赖**，应用升级可能会设计多个服务的修改
* **对运维基础设施的挑战较大**

## 1.3 组件服务化

传统实现组件的方式是通过库(library)，库是和应用一起运行在进程中，库的局部变化意味着整个应用的重新部署。 通过服务来实现组件，意味着将应用拆散为一系列的服务运行在不同的进程中，那么单一服务的局部变化只需重新部署对应的服务进程。我们用 Go 实施一个微服务：

* kit: 一个微服务的基础库（框架）
* service：业务代码+kit依赖+第三方依赖组成的业务微服务
* rpc + message queue（消息队列）：轻量级通讯

> <font color='#e54d42'>本质上就是多个微服务组合完成一个完整的用户场景/应用</font>

## 1.4. 按业务组织服务

工作模型改变：

从原本的烟囱式： `UI->中间件开发->测试->运维->监控` 改变为：**面向服务全栈**，`you build it, you fix it`, 对完成这项服务的整个流程负责，因为你是最清楚的

运维、测试等则负责开发更加高效的平台/工具提供开发人员使用

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20211030150042170.png" alt="image-20211030150042170" style="zoom: 50%;" />

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20211030150103522.png" alt="image-20211030150103522" style="zoom:50%;" />

## 1.5. 去中心化

每个服务面临的业务场景不同，可以针对性的选择合适的技术解决方案，但是注意不要过于的多样化。

去中心化主要分为以下几个方面：

* 数据去中心化：每个服务独享自己的数据存储设施（缓存、数据库等），隔离相关干扰（见图）
* 治理去中心化：防止热点服务崩溃、多部署负载均衡
* 技术去中心化：使用合适的技术解决合适的问题



<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20211030150309490.png" alt="image-20211030150309490" style="zoom: 50%;" />

## 1.6. 基础设置自动化

**无自动化不微服务**，自动化包括测试和部署。<u>单一进程的传统应用被拆分为一系列的多进程服务后</u>，意味着开发、调试、测试、监控和部署的复杂度都会相应增大，必须要有合适的自动化基础设施来支持微服务架构模式，否则开发、运维成本将大大增加。

* `CICD`：Gitlab + Gitlab Hooks + k8s
* `Testing`：测试环境、单元测试、API自动化测试
* 在线运行时：`k8s`，以及一系列监控 `Prometheus、ELK（日志采集）、Conrtol Panle`

企业的自动化流程：

![image-20211030151841269](http://xwjpics.gumptlu.work/qinniu_uPic/image-20211030151841269.png)

## 1.7. 可用性与兼容性设计

著名的 `Design For Failure `思想（**每一行代码都考虑是否会出错**），微服务架构采用粗粒度的进程间通信（**将请求设计为批量的请求**），引入了额外的复杂性和需要处理的新问题，如网络延迟、消息格式、负载均衡和容错，忽略其中任何一点都属于对“分布式计算的误解”。

可用性主要需要掌握以下几点：

* 隔离
* 超时控制
* 负载保护 
* 限流
* 降级
* 重试
* 负载均衡

一旦采用了微服务架构模式，那么在服务需要变更时我们要特别小心，服务提供者的变更可能引发服务消费者的兼容性破坏，**时刻谨记保持服务契约(接口)的兼容性。**

**发送时要保守，接收时要开放**。按照伯斯塔尔法则的思想来设计和实现服务时，发送的数据要更保守，意味着最小化的传送必要的信息，接收时更开放意味着要最大限度的容忍冗余数据，保证兼容性。

# 二、微服务设计

## 2.1 API Gateway的演进

原本的模式，按垂直功能进行了拆分，对外暴露一批微服务：

![O72Trc](http://xwjpics.gumptlu.work/qinniu_uPic/O72Trc.png)

但是缺乏统一的出口，面临困难：

* 客户端到微服务直接通信，强耦合。
* 需要多次请求，客户端聚合数据，工作量巨大，延迟高。
* 协议不利于统一，各个部门间有差异，需要端来兼容。
* 面向“端”的API适配，耦合到了内部服务。
* 多终端兼容逻辑复杂，每个服务都需要处理。
* 统一逻辑无法收敛，比如安全认证、限流。

<font color='#e54d42'>需要面向**用户业务场景**的API而不要面向资源的API，业务场景的需求才是根本</font>

所以需要内聚模式配合改进：

![CVEWwO](http://xwjpics.gumptlu.work/qinniu_uPic/CVEWwO.png)

​	新增了一个 `app-interface` 用于**统一的协议出口**，在服务内进行大量的 `dataset join`，按照业务场景来设计**粗粒度的 API**，给后续服务的演进带来的很多优势：

* 轻量交互：协议精简、聚合。
* 差异服务：数据裁剪以及聚合、针对终端定制化API。
* 动态升级：原有系统兼容升级，更新服务而非协议。
* 沟通效率提升，协作模式演进为移动业务+网关小组。

**BFF（Backend for Frontend）**面向前端场景的后端服务，主要负责**业务场景层聚合API**。BFF 可以认为是一种适配服务，将后端的微服务进行适配(主要包括聚合裁剪和格式适配等逻辑)，向无线端设备暴露友好和统一的 API，方便无线设备接入访问后端服务。

但是可能面临的问题就是单点故障，单一的BFF故障会导致全体崩溃。

改进：

![image-20211030154325953](http://xwjpics.gumptlu.work/qinniu_uPic/image-20211030154325953.png)

多BFF分类负责聚合API服务，<font color='#e54d42'>每个BFF核心负责的其实是**数据的组装**（从各个下游API中组装数据）</font>

BFF设计模式也叫做API聚合：

![PCg8mS](http://xwjpics.gumptlu.work/qinniu_uPic/PCg8mS.png)

但是当业务多了之后，BFF的数量也逐步上升，更新一个下游横向切面的模块会导致非常多的BFF跟着需要更新，很多**跨横切面逻辑**，比如**安全认证，日志监控，限流熔断**等。随着时间的推移，代码变得越来越复杂，技术债越堆越多。

改进：将所有面向横向切面的服务都放在最上层引入`API Gateway`, 把业务集成度高的BFF层和通用功能服务层`API Gateway`进行了分层处理

![NazW3s](http://xwjpics.gumptlu.work/qinniu_uPic/NazW3s.png)

在新的架构中，网关承担了重要的角色，它是解耦拆分和后续升级迁移的利器。在网关的配合下，单块 BFF 实现了解耦拆分（不需要关心横向切面的服务），各业务线团队可以独立开发和交付各自的微服务，研发效率大大提升。另外，<u>把跨横切面逻辑从 BFF 剥离到网关上去以后，BFF 的开发人员可以更加专注业务逻辑交付</u>，实现了架构上的**关注分离(Separation of Concerns)**。

我们业务流量流转过程实际为：

移动端 -> API Gateway -> BFF -> Mircoservice（微服务），在 FE Web业务中，BFF 可以是 nodejs 来做服务端渲染(SSR，Server-Side Rendering)，注意这里忽略了上游的 CDN、4/7层负载均衡(ELB) （这些都是在API Gateway之上）。

**BFF与API Gateway的区别：**

* BFF主要负责下游**数据**的组装，拒绝涉及横向切面的业务
* API Gateway则主要负责横向切面的业务（限流、账号限权等）

## 2.2 Mircoservice的划分

如何划分微服务的边界，每个业务场景微服务划分的依据是不同的

在实际项目中通常会采用两种不同的方式划分服务边界，即通过**业务职能(Business Capability)**或是 **DDD 的限界上下文(Bounded Context)**。

* `Business Capability` 业务职能
      由公司内部不同部门提供的职能。例如客户服务部门提供客户服务的职能，财务部门提供财务相关的职能。
* `Bounded Context` 限界上下文
      限界上下文是 DDD 中用来划分不同业务边界的元素，这里业务边界的含义是“解决不同业务问题”的问题域和对应的解决方案域，为了解决某种类型的业务问题，贴近领域知识，也就是业务。

![mb2Zfh](http://xwjpics.gumptlu.work/qinniu_uPic/mb2Zfh.png)

<u>能够闭环的解决用户的一个应用场景的就应该设计为一个服务</u>

**CQRS（Command Query Responsibility Segregation）**将应用程序分为两部分：**命令端和查询端**（简单来说就是读写分离）。命令端处理程序创建，更新和删除请求，并在数据更改时发出事件。查询端通过针对一个或多个物化视图执行查询来处理查询，这些物化视图通过订阅数据更改时发出的事件流而保持最新. 

![D4b9jw](http://xwjpics.gumptlu.work/qinniu_uPic/D4b9jw.png)

在稿件服务演进过程中，我们发现围绕着创作稿件、审核稿件、最终发布稿件有大量的逻辑揉在一块，其中稿件本身的状态也有非常多种，但是<u>最终前台用户只关注稿件能否查看</u>，我们依赖稿件数据库 `binlog` 以及订阅` binlog `的中间件` canal`，将我们的稿件结果发布到消息队列 `kafka` 中，最终消费数据独立组建一个稿件查阅结果数据库，并对外提供一个独立查询服务，来拆分复杂架构和业务。

我们架构也从 `Polling publisher` -> `Transaction log tailing` 进行了演进(Pull vs Push)。

## 2.3 Mircoservice安全

对于外网的请求来说，我们通常在` API Gateway` 进行统一的认证拦截，一旦认证成功，我们会使用` JWT` 方式通过` RPC` 元数据传递的方式带到 `BFF `层，`BFF` 校验` Token` 完整性后把身份信息注入到应用的 `Context `中，`BFF` 到其他下层的微服务，建议是直接在` RPC Request `中带入用户身份信息(`UserID`)请求服务。

* API Gateway -> BFF -> Service    
* Biz Auth  -> JWT -> Request Args

对于服务内部（内网安全），一般要区分身份认证（`jrpc`证书等方式）和授权（`RBAC`等）。

* `Full Trust` （知道身份，通讯过程也加密）
* `Half Trust `（知道身份，通讯过程不加密）
* `Zero Trust` （都可以连接）

![dPseq0](http://xwjpics.gumptlu.work/qinniu_uPic/dPseq0.png)

授权变化：用户`Token -> JWT Token -> Access Token（内网token）-> 用户ID`

# 三、gRPC与服务发现

## 3.1 gRPC

### 1. 什么是RPC？

对比表解释：

| 名词   | 特点                                                         |
| ------ | ------------------------------------------------------------ |
| RPC    | 远程过程调用（分布式、微服务间的方法调用）                   |
| HTTP   | 无状态，每次请求都要发送一个request，服务器响应之后就断掉（http header中的keep-alive指的是tcp） |
| TCP    | 面向连接，三次握手保证通信可靠                               |
| UDP    | 非面向连接，不可靠，速度快（可以手动对数据收发进行验证，IM系统多采用，QQ） |
| socket | TCP协议的接口实现，面向传输层进行网络编程                    |

**RPC是一种网络调用设计、框架，其面向服务而不是通信协议**。使用的通讯协议只是其中的一部分，其中可能使用的就是`Http`协议，是在`Http`协议概念的上层，其主要**在上层构建的一些优化通信**，例如：负载均衡、寻址、序列化与反序列化

### 2. grpc

官网的解释： `“A high-performance, open-source universal RPC framework”`

gRPC是谷歌开源的一个 **RPC 框架**，面向移动和 **HTTP2** 设计。

- 内容交换格式采用**ProtoBuf**(Google Protocol Buffers)，开源已久，提供了一种灵活、高效、自动序列化结构数据的机制，作用与XML，Json类似，但使用二进制，（反）序列化速度快，压缩效率高。
- 传输协议 采用`http2`，性能比`http1.1`好了很多

和很多RPC系统一样，服务端负责实现定义好的接口并处理客户端的请求，客户端根据接口描述直接调用需要的服务。客户端和服务端可以分别使用gPRC支持的不同语言实现。

`ProtoBuf `具有强大的IDL（interface description language，接口描述语言）和相关工具集（主要是protoc）。用户写好.proto描述文件后，protoc可以将其编译成众多语言的接口代码。

![L9rv1Z](http://xwjpics.gumptlu.work/qinniu_uPic/L9rv1Z.png)

gRPC的优势：

* 多语言：语言中立，支持多种语言。
* 轻量级、高性能：序列化支持 `PB(Protocol Buffer)`和 `JSON`，`PB` 是一种语言无关的高性能序列化框架。
* 可插拔
* IDL：基于文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub。
* 设计理念
* 移动端：基于标准的 `HTTP2 `设计，**支持双向流、消息头压缩、单` TCP` 的多路复用、服务端推送**等特性，这些特性使得 `gRPC` 在移动端设备上更加省电和节省网络流量。

![X1R8Ap](http://xwjpics.gumptlu.work/qinniu_uPic/X1R8Ap.png)

* **服务而非对象、消息而非引用**：促进微服务的系统间粗粒度消息交互（批量接口）设计理念。

  如图所示`service`并不是一个对象，`message`也不是一个引用

  ![tBSJr3](http://xwjpics.gumptlu.work/qinniu_uPic/tBSJr3-20211030190848785.png)

* 负载无关的：不同的服务需要使用不同的消息类型和编码，例如 `protocol buffers`、`JSON`、`XML` 和 `Thrift`。
  
* 流：`Streaming API`。
  
* 阻塞式和非阻塞式：支持异步和同步处理在客户端和服务端间交互的消息序列。

* 元数据交换：常见的横切关注点，如认证或跟踪，依赖数据交换。

* 标准化状态码：客户端通常以有限的方式响应 API 调用返回的错误。

* grpc的定义规范严苛，输入输出都是约定好的，而json+http的方式一般对于json的格式时不做约束的，比较宽松，http表达能力弱，并且每一个request都需要等到response，这在内网时不需要的。

### 3. HealthCheck

`gRPC` 有一个标准的健康检测协议（**内置**），在` gRPC` 的 所有语言实现中基本都提供了生成代码和用于设置运行状态的功能。

**<u>主动</u>健康检查 *health check*，可以在服务提供者服务不稳定时，被消费者所感知，临时从负载均衡中摘除，减少错误请求。**当服务提供者重新稳定后，*health check* 成功，重新加入到消费者的负载均衡，恢复请求。

 *health check*，同样也被用于<u>外挂</u>方式的容器健康检测， 或者流量检测*(k8s liveness & readiness)*。

> <font color='#39b54a'>服务发现/注册的两种方式：</font>
>
> <font color='#39b54a'>**主动注册：**当服务提供方初始化完成后主动发送消息给服务发现方注册</font>
>
> <font color='#39b54a'>**外挂方式：** k8s中通过不断检测一个服务提供者的healthCheck接口，一旦发现其服务可用后就帮其在Discovery中注册</font>

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20211208201221609.png" alt="image-20211208201221609" style="zoom:50%;" />

**平滑发布/下线：**

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/VdTLiF.png" alt="VdTLiF" style="zoom:50%;" />

平滑下线的一般流程：

1. 向服务提供方发送`kill`信号(`SIGTERM`优雅的退出)

2. 向服务注册/发现方发送一个注销请求，注销自己
3. 将自己返回给health check的响应设置为失败，优雅的退出
4. 使用grpc的`shutdown`接口
5. 如果发现服务提供方容器一直无法退出（10～60s内），那么就强制`kill -9`发送`SIGKILL`信号退出

### 4. 服务发现-客户端发现









# 四、多集群与多租户



