---
title: 使用Prometheus监控报表信息采集优化.md
tags:
  - null
categories:
  - technical
  - Prometheus
toc: true
declare: true
date: 2022-01-11 16:10:20
---

# 一、开发目的/原因

两个问题：

* 未来HCI平台需要支持大量的虚拟机（48个物理节点2000台虚拟机），每个虚拟机都独立保存自己的报表数据，获取报表数据要跨主机通信。虚拟机过多这样的操作性能就极具下降
* HCI中的很多服务程序自带独立采集所需数据，缺乏一个统一的规划，导致数据大量的重复采集

对现有的数据采集、存储、消费等相关流程进行梳理，并重新设计，统一规划，希望最终达成这样的**目标**：

* 全部的数据使用统一的框架采集，并集中存储。
* HCI其他模块不再独自采集数据，需要数据时，从报表和状态中心获取。

# 二、旧版架构与问题

每个节点部署一个`vtp-data-reportd`（报表数据抓取服务），以及一个`vtp-datareport-server`（报表服务主程序，接收数据，写入RRD，响应外部查询请求），每个节点各自保存本节点的报表数据到本地RRD文件。

旧版本架构：

![image-20220307110611863](http://xwjpics.gumptlu.work/image-20220307110611863.png)

<!-- more -->

这个方案存在几个问题：

* 数据分布存储

  查询时需从相应节点获取数据，涉及跨主机通信，性能相对较差。不便于导出数据、聚合分析。若虚拟机运行位置切换，只能查询到该虚拟机在新节点上运行产生的趋势数据。（也就是旧报表数据没有移植保存）

* 重复数据采集。

  除了报表服务之外，还有很多服务（比如，告警，DRS/集群资源调度等等）独自采集数据，独自维护状态，存在重复的数据采集行为，浪费系统资源。

# 三、新架构选型

三种监控的候选方案以及优劣如下表：

|          | prometheus                                                   | ceilometer                                                   | Nightingale夜莺（滴滴）                                      |
| -------- | :----------------------------------------------------------- | ------------------------------------------------------------ | :----------------------------------------------------------- |
| **背景** | Prometheus是由SoundCloud开发的开源监控告警系统和时序列数据库 | Ceilometer项目是OpenStack中用来做计量计费功能的一个组件，后来又逐步发展增加了部分监控采集、告警的功能 | Nightingale（夜莺，简称n9e）是滴滴开源的一个企业级监控解决方案。 |
| **优点** | 1、server轻量<br />2、exporter采集器拓展性强，适配各个语言并且社区已有功能丰富<br />3、强大的PromQL可以对多个指标加法、连接等操作<br />4.适应k8s容器化生态 | 1、拓展性好，支持自定义采集插件<br />2、功能较为完善<br />3、支持对接其他时序数据库`InfluxDB`、`OpenTSDB` | 1、通过底层的RRD数据库与分布式一致性hash数据分片实现了分布式时序存储系统<br />2、借鉴OpenTSDB在数据模型中引入Tag，这样能支持多维度的聚合统计以及告警规则设置，大大提高了使用效率。<br />3、也支持自定义插件，拓展性好 |
| **缺点** | 1、 不提供集群化的高可用方案<br /> 2、自带时序数据库不能降采样,不能替换自带时序数据库组件 | 1、容器化支持较少<br />2、社区不活跃维护风险<br />3、组件多部署维护较困难 | 1、整体发展一般，局限于国内的一些互联网公司<br />2、组件较多维护不方便 |

所以，综上所述因为后期也要使用容器化的部署、k8s的编排所以`Prometheus`是一个最佳的选择

# 四、Prometheus架构

新版的报表服务，全部的数据使用统一的框架采集，并集中存储，有效避免上述问题。其工作原理如下：

* 计算节点：

  每个节点部署一个`Exporter`实例，用于采集本节点的指标数据，包括虚拟机，物理机，虚拟机网络等等；  （本节点的指标数据）同时部署一个`Pushgateway`实例，用于接收本节点自定义脚本推送的指标数据，供`Prometheus`抓取。 （本节点其他指标数据（用自定义脚本实现））

* 主控节点：

  主控节点部署一个`Prometheus`实例，负责定时从所有节点的`Exporter`和`Pushgateway`拉取数据，并将其中的状态数据发送给状态中心`statuscenterd`，趋势数据则写入内置的`TSDB`。

  Prometheus自身只保留最近1小时数据（热数据，位于内存中），更长时间的历史数据使用RRD进行归档。rrd-adapter每隔1分钟向Prometheus发送http请求获取数据，经过解析转换之后归档到RRD文件。

* `status-centerd`负责响应和分发外部请求，最近1小时数据从`Prometheus`获取，更长时间的历史数据则从RRD文件获取。

* 主控每隔1小时向两个备选节点增量同步RRD所在的loop文件（使用rsync）。

架构如下：

![image-20220307111324814](http://xwjpics.gumptlu.work/image-20220307111324814.png)

# 五、应用场景

| 特性                   | 应用场景                                                     |
| ---------------------- | ------------------------------------------------------------ |
| 数据可视化             | 查看指定资源（如，物理机，虚拟机等等），指定指标（如，CPU使用率，温度等）的趋势图 |
| 基于趋势数据的告警推送 | 监控指定资源（如，物理机，虚拟机等等），指定指标（如，CPU温度等），当指标值超过设定阈值持续一段时间时，主动向告警处置模块推送告警消息 |
| 未来需求               | 数据导出，大数据分析，AI运维，智能调度，告警自愈等等         |

# 六、Prometheus架构的改进过程

## 问题一：长时间历史数据存储问题

`Prometheus`本身自带基于本地存储的TSDB，但不支持`Downsampling`（降采样，即将多个细粒度的数据点通过均值等方式，合并成一个粗粒度的数据点），无法存储长时间的历史数据。

降采样问题
存储长时间的历史数据，通常的做法都是降采样（`Downsampling`）。即通过降低数据精度，来达到存储更长时间历史数据的目的。比如，12个5秒精度的点，通过计算均值，合并成1个1分钟精度的点。

**替换一个支持降采样的时序数据库：**

`InfluxDB`：简单不依赖第三方环境，操作函数丰富，但是资源消耗较大

`OpenTSDB`：依赖于`HBase`，存储量大且快，但是架构也更复杂

`RRD`：使用固定大小的空间来存储数据，并有一个指针指向最新的数据的位置，圆心指向每个存储点，没有结束点，当一个圆都存储满了之后就将就将最开始的数据覆盖；非常简单，但是要自研高可用

**综合熟悉程度以及需求的简单性选择了RRD数据库作为长时间历史数据的降采样数据库**

## 问题二：高可用问题。

`Prometheus`是一个单机方案，本身不提供高可用能力。主要解决两个方面的高可用：

* `Prometheus`的高可用
* `RRD`的高可用

### Prometheus的高可用

**方案一：每个主控节点上都部署一个`Prometheus`服务器实例**

每个控制节点部署一个`Prometheus`实例，仲裁节点除外。
当`Exporter`收到主控制节点`Prometheus`实例的pull请求时，开始采集本节点当前指标数据，并在内存中缓存数据；当`Exporter`收到其他控制节点`Prometheus`实例的pull请求时，直接返回内存中缓存的数据，避免重复采集。当主控离线时，其他控制节点报表服务仍然可正常工作，基本没有切换开销。
总的来说，方案1就是堆计算资源，来换取服务的高可用。

**方案二：主控部署Prometheus实例+rsync同步（选择的方案）**

其他控制节点使用rsync定时增量同步RRD文件。
当主控离线时，从其他正常的控制节点中挑选一个节点，启动`Prometheus`和报表服务（`statuscenterd`）实例。只同步一个控制节点，切换主控有问题。有可能会切到没有数据的控制节点上。做成可配置的，默认只同步到一个控制节点。数据量不大，可以同步2份

![image-20220307111324814](http://xwjpics.gumptlu.work/image-20220307111324814.png)

### `rrd-adapter`适配器

`Prometheus`和`RRD`之间对接需要一个适配器来做格式转换工作：

适配器定时向Prometheus的实例发送http请求，获取所需数据。再将接收到的数据经过格式转换之后，存入`RRD`数据库。

## 问题三：数据采集方式

`Prometheus`将所有采集到的数据都按照时序数据来存储，并且内存缓存了最近一段时间的指标数据。

对于有些数据，我们只关心其当前值，不关心其趋势，这类状态数据如果也按时序数据来存储，则会存在内存和磁盘资源的浪费。所以，对于只需要当前值的状态数据，需要更改其存储方式。

我们又希望状态数据和趋势数据的采集，可以共用一套采集框架。而`Prometheus`启动时，因为要加载数据到内存，会比较耗时，这期间无法采集状态数据，对于状态中心服务来说，这一点不可接受。

**方案1：引入一个中间层Prometheus**

引入一个中间层`Prometheus`，定时采集数据，并缓存到内存，同时它还接收从`Pushgateway`推送过来的数据，并将状态数据发送到状态中心服务`statuscenterd`

优点：

* 独立组件，不依赖`Prometheus`，可独立运行。当实例挂掉时，可以立即被拉起，启动耗时较短。
  不涉及`Prometheus`源码改动，开源组件与业务解耦，更便于维护。

* 支持完全的推送机制，可以从计算节点底层脚本推送`Pushgateway`，`Pushgateway`再推送到控制节点`Prometheus`，`Prometheus`再推送到其他接收方。


缺点：

* 虽不涉及源码改动，但基本相当于在外部实现一个`scrape`组件。诸如配置解析，定时采集，服务发现等等，都需要中间层`Prometheus`来处理。存在冗余。
* 数据时效性相对较差，中间层`Prometheus`定时采集之后，再被`Prometheus`定时采集，时效性较差。

**方案2：改造Prometheus内部scrape组件（选择的方案）**

改造`Prometheus`内部`scrape`组件，定时从`Exporter`拉取数据，如果是状态数据，则发送给状态中心服务`statuscenterd`，如果是趋势数据则写入自带的`TSDB`

优点：

* 工作量较少。源码改动难度适中，只需在scrape获取到数据之后，新增一个处理状态数据的分支即可。
  数据时效性相对较好。仅`Prometheus`定时采集，时效性相对较好。
* 涉及`Prometheus`源码改动，开源组件与业务耦合，不便于后续维护。并非完全是推送方式，`Prometheus`到`Pushgateway`属于定时拉取方式。
