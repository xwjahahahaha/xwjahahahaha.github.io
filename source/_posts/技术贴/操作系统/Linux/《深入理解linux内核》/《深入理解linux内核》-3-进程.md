---
title: 《深入理解linux内核》-3-进程
tags:
  - null
categories:
  - technical
  - null
toc: true
declare: true
date: 2022-07-30 19:45:23
---

[TOC]


<!-- more -->

> 学习自书籍：
>
> * 《深入理解linux内核》第三章

# 进程

## 1. 浅述linux进程、用户线程、轻量级进程LWP的历史发展？

linux中发展可总结为：进程 => 用户线程 => 轻量级进程

**进程**：如果遵循传统OS中的概念可概括为：一个程序执行的实例，包含了此程序已经执行到何种程度的数据结构对象的汇集，同时从内核的角度看来，也是分配系统资源（cpu、内存）的基本实体

现代的Unix系统已经支持了多线程的应用程序，但是在早期并没有支持多线程应用程序，而是借助一种**用户态线程**的实现，与认知中的线程一样，都是代表一个执行流，但是最大的区别在于其是依靠**在用户态程序管理多个执行流的创建、处理、调度的**（与现在的golang的协程类似）

这就带来了问题：在内核看来仍然只是一个进程一个执行流，多用户态线程非阻塞切换逻辑非常复杂且低效（自己在用户态干了内核进程调度、切换的事）所以这样的方式就逐渐被淘汰

随后就出现了`lightwetght process(LWP)`轻量级进程，提供了堆多线程应用程序更好的支持，其通过多个进程共享一些资源（地址空间、打开的文件等）实现轻量（当然，共享访问的时候也就需要同步机制），同时每个进程都是一个单独的执行流，对于内核来说也可以直接当做单独的进程调度、切换，这其实也就是我们常说的线程

目前大多数多线程应用程序都是使用`pthread (POSIX thread)`库的标准函数集编写的

## 2. 进程描述符与task struct

进程描述符`process descriptor`是用来干嘛的？

=> 内核用于清楚的了解当前进程的状态信息/描述信息，例如打开了什么文件？你的调度优先级是什么？你的地址空间的分配？…

进程描述符都是`task_struct`结构的（如下图，并非全貌图），在linux中经常将进程成为任务task/线程thread

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220730203027416.png" alt="image-20220730203027416" style="zoom: 40%;" />

进程描述符中有很多字段都是指向其他数据结构的指针，右边六个数据结构都是涉及进程所拥有的特殊资源，但是在此章中只介绍进程的状态和进程父子关系

## 3. 进程状态种类？僵尸进程状态？如何设置进程状态？

如上图所示，进程的状态在`state`字段中展示，他是一组标志组成，每个标志描述一种可能的进程状态，状态是互斥的，所以一个进程严格来说只能设置一种状态

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220730204242282.png" alt="image-20220730204242282" style="zoom:50%;" />

此外还有两种状态即可放在`state`中也可放在`exit_state`中，从名字就可以看出都是进程退出/终止的时候才会变为这两种其中的一种：

* 僵死状态(`EXIT_ZOMBIE`)

  进程的执行被终止，但是，父进程还没有发布`wait4()`或` waitpid()`系统调用来返回有关死亡进程的信息，因为在父进程这些系统调用之前内核不能丢弃包含在已结束进程的进程描述符中的数据与资源

* 僵死撤销状态(`EXIT_DEAD`)

  最终状态，父进程刚发出`wait()`系统调用，系统将死进程回收删除。设置此状态的原因在于，可能有多个进程在`wait`此进程，所以是为了防止竞态而用作同步

设置进程状态的相关语句：

`p->state= TASK_RUNNING;`

或者使用`set_task_state`、`set_current_state`等内核代码提供的宏

## 4. 如何标识一个进程？内核识别？用户态识别？pid？tgid又分别是什么？

如何标识一个进程？

首先因为进程与其描述符之间是严格的一对一关系（即使是共享数据的多个轻量级进程），所以唯一标识一个进程是有意义的

在内核态：直接使用32位进程描述符**地址**标识进程

在用户态：也就是我们熟悉的`PID`

pid是有上限的，具体描述位置在`/proc/sys/kernel/pid_max`中，每次分配都是递增+1的分配，一旦达到上限，那么就会复用之前已经销毁的进程的pid，内核是通过保存一个位图来记录哪些已分配哪些空闲的，并且这个位图存放在一个物理页框中不会释放，比较有意思的是默认的pid max值是32767就等于页框32768位-1

在另一方面，Unix程序员期望同一组中线程有共同的PID，例如当一个信号发送过来之后所有LWP/线程都能收到并处理，所以后来就引入了`tgid`也就是线程组ID，其值等于线程组的第一个进程的pid，存在进程描述符的tgid字段，需要注意的是`getpid()`系统调用返回的是当前进程的tgid而不是pid

## 5. 内核保存进程描述符的处理：thread_info线程描述符与内核栈联合结构

一个进程的生命周期是难以确定的，有的几秒钟有的几个月，所以进程描述符不能够存储在静态内存区域（也就是永久分配的区域），所以需要放在**用户内存区而不是内核内存区**（或者说用户态地址空间与内核态地址空间？），因为用户内存区是动态内存可以分配与回收

那么问题来了：<font color='#e54d42'>既然放在用户内存区，内核如何知晓一个进程的进程描述符呢？</font>

=> Linux**将两个紧凑的数据结构存放在一个单独为进程分配的存储区域内**（当然也就是在内核内存区），通常的大小为两个**连续**页框8K（并且为了效率第一个页框的起始地址是2^13的倍数）

* `thread_info`: 线程描述符

* 内核进程堆栈，因为内核控制路径使用很少的栈，所以8K是足够的

  > 进程的内核堆栈是和`thread_info`放在一起的，内核为每一个进程维护了这样的一个结构

整个存储区域如下图：

![image-20220730213848590](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220730213848590.png)

堆栈由高地址向低地址拓展，底部是`thread_info`结构，`task`和`thread_info`两个指针使得进程描述符与线程描述符互相指向

`esp`寄存器指向栈顶（或者说保存了栈顶地址），随着栈的扩大不断其值不断减小

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220730214125166.png" alt="image-20220730214125166" style="zoom:50%;" />

可使用`alloc_threaad_info`和`free_thread_info`宏分配和释放存储这个内存区的这两个结构

## 6. 内核如何快速索引当前内核进程的用户态进程描述符？

内核提供了一个非常巧妙的方式可以实现从当前内核栈esp指针地址直接找到进程描述符，流程如下：

首先获取`thread_info`，内核中`current_thread_info()`函数的汇编实现如下：

![image-20220730215240312](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220730215240312.png)

可以看出对于当前esp指向的内核栈顶地址来说，如果此内存区域是8K大小，那么就是如图所示的将esp地址的低13位屏蔽掉就ok了，如果是4K大小，那么就将低12位屏蔽即可，例如上面图中屏蔽之后得到的地址就是`0下05fa000`，这就是thread_info的首地址

下一步就是获取thread_info的task地址，因为其指向进程描述符，巧的是，task地址就是thread_info中偏移量为0的地址，所以`current_thread_info->task`函数的汇编指令如下：

![image-20220730215730911](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220730215730911.png)

（其实没差）执行完这三条指令就在P中获取到了当前内核进程的用户态进程描述符地址，然后做进一步的操作…

在多核处理器中这样的实现优势明显，省略了需要额外全局变量标识正在运行的进程的描述符

## 7. 内核中常使用的数据结构：双向链表

内核中经常使用的双向链表结构如图所示：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814194709930.png" alt="image-20220814194709930" style="zoom: 50%;" />

next、prev指针不必多说，这两个指针都包含在`list_head`的结构中，但是其中需要注意的是，这两个指针存放的地址不是上一个/下一个链表节点的地址（整个数据结构的地址），**而是上一个/下一个的`list_head`结构体的地址**

具体创建的宏是`LIST_HEAD(list_name)`，相关的操作包括：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814195050175.png" alt="image-20220814195050175" style="zoom:50%;" />

## 8. 进程链表：连接起来的进程描述符(对应task_struct中的task字段)

进程链表将**所有的**进程描述符连接起来，每个进程的进程描述符`task_struct`都有一个`task`字段(`list_head`类型)，此类型连接前后双向的其他`task_struct`

整个链表的头是`init_task`描述符，也就是对应了系统的`init`进程（0号进程）

> init_task的pre指向什么？ => 就是最后插入的task_struct的task字段啊，别忘记了双向链表

## 9. TASK_RUNNING状态的进程链表数据结构的演变（对应run_list字段）

`TASK_RUNNING`状态的进程是可运行状态的进程，也是内核想要寻找下一个进程时需要找的进程

早期的实现中，内核将所有可运行进程都放在一个**运行队列**中，但是这样的实现问题在于依靠进程的优先级排序开销很大，并且在选择最佳进程的时候还需要全局扫描

后来的实现的目的就是：<font color='#39b54a'>在一个**固定的时间**内选出最佳运行进程，这与队列中的进程数无关</font>

具体实现思路是：

* 建立多个可运行进程链表，每个优先级权重(0～139)的对应一个链表，每个`task_strcut`中包含一个`list_head`类型的字段`run_list`，其用于将当前进程链入对应优先级的进程链表中

  > * 进程的动态权重位于其进程描述符的`prio`字段
  > * 多核处理器情况下，每个CPU都会维护自己的一个这样的进程链表集合

* 上述的所有链表，共140个，都是由如下的`prio_array_t`实现的：

  <img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814200909741.png" alt="image-20220814200909741" style="zoom:50%;" />

* 可以通过`enqueue_task(p, array)`插入当前进程到对应优先级的链表中，其中的参数`array`是一个指向`prio_array_t`的指针，其实现等价于：

  ![image-20220814201502560](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814201502560.png)

> `run_list`和`task`都是进程的list_head类型的一个链表节点，那么两者的区别是什么？
>
> * 区别在于`task`是用于将当前进程描述符/进程链入到**所有**进程链表中，而`run_list`则是链入到**可运行**的链表中（对应权级）

## 10. 进程之间的关系表示

进程之间有父子关系，同父进程的多个子进程之间是兄弟关系，所以需要在进程描述符中引入几个字段来描述：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814202030352.png" alt="image-20220814202030352" style="zoom:67%;" />

`real_parent`与`parent`都是指向父进程，区别点在于，前者是指向创建P时的父进程，后者是当前的父进程，但是两者一般来说是相同的

p0创建了p1、p2、p3，而随后p3又创建了p4，其关系如下：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814203743911.png" alt="image-20220814203743911" style="zoom:67%;" />

除了如上的关系，进程之间还可能有其他关系：是同一个进程组、登录会话、线程组等等（这些都是非亲属关系）

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814204015486.png" alt="image-20220814204015486" style="zoom:67%;" />

## 11. pid与进程描述符的映射关系：较为复杂的pidHash表结构

在很多情况下，内核必期望从进程的Pid导出进程的描述符（例如kill、发送信号等）

顺序扫描的效率是不能接受的，随后就出现了hash表的结构：

为了加速查找出现了4个hash表，对应了不同类型Pid字段，每种都有自己的Hash表：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814204300596.png" alt="image-20220814204300596" style="zoom:67%;" />

这四个散列表用一个pid_hash数组保存，对于每一个类型的hash表来说，key还需要经过一步映射（使用`pid_hashfn`函数）为表索引

出现了hash映射就代表着会出现冲突，具体来说就是两个相同的pid经过这样的函数映射之后得到同一个表索引

内核是如何处理这样的冲突的呢？

=> 链表处理，对于每一个表项都是由冲突进程描述符组成的双向链表

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814205115364.png" alt="image-20220814205115364" style="zoom:67%;" />

目前这样的结构还有一个问题：如果内核期望快速拿到一组进程的进程描述符？（在很多场景下期望直接对一组进程操作）

这样就催生出了对应hash表内部更加复杂的结构：

对于上图的PID更为详细的结构如下表：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220814205731992.png" alt="image-20220814205731992" style="zoom: 50%;" />

* **同组的多个进程使用`pid_list`连接**
* **hash冲突的多个pid通过`pid_chain`连接成为一个链表**

## 12. 内核如何组织进程？

为了快速检索的需求，内核需要构建进程的运行队列：

* 将所有处于运行`TASK_RUNNING`状态的进程组织在一起（具体结构也就是上面所述）
* 其他状态`TASK_STOPPED`、`EXIT_ZOMBIE`、`EXIT_DEAD`因为比较简单，所以不需要使用特殊的数据结构（可以直接用pid访问）

* 根据不同的特殊的事件将`TASK_INTERRUPTIBLE`和`TASK_UNINTERRUPTIBLE`这两种不同状态的进程细分为许多类，每一类都对应某个特殊的事件，所以引入了新的数据结构（也是进程链表）：**等待队列**

## 13. 等待队列与唤醒

### 等待队列

等待队列再内核中的作用有很多：

* 中断处理
* 进程同步和定时

进程经常会等待某些事件的发生，例如访问IO、等待系统资源等等，等待队列的实现是在**事件上**的等待，每条等待队列都唯一的对应于一个特殊事件，在此事件上等待的进程就会把自己放在此等待队列中，所以等待队列就是表示<font color='#e54d42'>一组为一个特定事件等待而睡眠的一系列进程</font>，当某一个条件为真的时候，内核就会唤醒他们

等待队列也是由双向链表实现：

每个等待队列都有一个等待队列头的结构：

![image-20220821111444947](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220821111444947.png)

其中等待队列的元素类型结构如下：

![image-20220821111717265](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220821111717265.png)

每一个元素就代表一个等待进程（节点中的`task_struct`字段）

### 唤醒

一般为了避免惊群效应，所以不会直接将整个等待队列的所有进程直接全部唤醒，而是唤醒一个

> 惊群效应：对于一个互斥的资源，唤醒了一群进程去争抢，最后只有一个成功消费，其他进程又要回去睡眠

由此衍生了以下两种类型：

* 互斥进程，一次只唤醒一个，他们的等待队列的节点`flag`都为1，内核会有选择的唤醒
* 非互斥进程，`flag`为0，总是由内核在事件发生后唤醒 /都被唤醒（例如需要为等待磁盘传输结束的一组进程，此时就需要将他们都被唤醒）

等待队列中的元素的`func`字段就决定了睡眠中的进程应该用什么方式唤醒（内核开发者可以自定义此函数）

`TASK_INTERRUPTIBLE`和`TASK_UNINTERRUPTIBLE`这两种不同状态的进程唤醒的区别具体来说其实就是：

* 前者接收到一个信号就可以唤醒当前的进程

具体等待队列的一些函数操作见书P102

## 14. 进程的资源限制(rlimit)

每个进程都有一组相关的资源限制，限定了进程能够使用系统资源的数量，具体的如下表：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220821113024306.png" alt="image-20220821113024306" style="zoom:50%;" />

对当前进程的资源限制存放在`task_struct->signal->rlim`字段，在进程的信号描述符的一个字段中，这个字段是一个rlimit的结构数组：

![image-20220821113359119](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220821113359119.png)

超级管理员可以通过`getrlimit()`或者`setrlimit()`系统调用来提高`rlim_max`的上限

注意与`cgroup`的主要区别：

* cgroup主要用于将限制作用于一组进程
* rlimit限制的是单个进程
* 两者都能做限制，但是互相独立，其实除了这些限制意外系统本身还有很多限制，所以一个进程的限制可以有多个但是都必须全部满足在其内

## 15. 进程切换的详细流程

什么是进程切换：操作系统挂起某个正在运行的进程，并恢复之前某个挂起进程的运行

### 硬件上下文

所有进程有自己的虚拟地址空间，但是需要共享CPU的寄存器，所以需要保证CPU寄存器的上下文环境的切换

必须装入寄存器的数据称之为**硬件上下文**，其是进程上下文/可执行上下文的一个子集

linux中具体存放在哪？

* 一部分存放在TSS段（任务状态段，注意是老版本intel的原始设计保存在这里，之后被取消）
* 一部分存放在内核堆栈中（也就是上面说的，和`thread_info`存放在一起）

切换方式的发展：

* 最早是使用硬件支持来切换的，通过`far jmp`指令跳到下一个进程的TSS段描述符的选择符（修改寄存器的值），cpu会自动保存原进程的硬件上下文（到其TSS和内核堆栈）并重放新的硬件上下文

  > 缺点：硬件不会检查ds和es段寄存器的值

* 现在转为使用一组`mov`指令（软件层面）切换，这样可控制性更高一些，性能也差不多

进程切换的过程在**内核态发生**，在切换之前上一个进程的所有寄存器内容都已经保存在内核堆栈上了（包括ss和esp这对描述用户态堆栈地址的寄存器）

### 任务状态段TSS

8086体系结构的一个特殊段类型，叫做**任务状态段**`TSS`，专门用于存放硬件上下文

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220821120041881.png" alt="image-20220821120041881" style="zoom:67%;" />

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220821120113487.png" alt="image-20220821120113487" style="zoom:50%;" />

一个TSS段对应于一个CPU（注意Linux中一对一的不是进程，就像一个GDT对应于一个CPU一样）

虽然Linux中不使用硬件上下文，但是还是会为每个CPU创建这样的TSS段

其主要功能就是（或者说存储的值是）：

* 当一个CPU从用户切换到内核态的时候，其要从TSS段中获取**内核态堆栈的地址**
* 一个用户态进程通过in或者out指令访问一个IO端口的时候，会**从TSS中获取IO许可权位图**，判断自己是否有权利访问

每次进程切换的时候内核都更新TSS的某些字段以便相应的cpu控制单元可以安全的检索到它需要的信息

因此TSS反应了当前在CPU上运行的进程的特权级别，但是没有运行的进程并不会保留其TSS

Linux中每个CPU的`tr`寄存器包含了相应的TSS的TSSD选择符（TSSD：任务状态段描述符），也包含了两个非编程字段：TSSD的Base字段和Limit字段，这样CPU就可以直接对TSS寻址而不用从GDT中检索TSS的地址

所以：<font color='#e54d42'>对于Linux来说，目前TSS只用做给CPU一对一使用的保存权级切换时的内核态堆栈地址以及IO许可的权级位图，并不会保存进程切换的某个进程的硬件上下文</font>

### thread字段

如上所述，硬件上下文必须保存在别处而不在TSS中，因为TSS针对的是CPU

具体的目前Linux将硬件上下文信息保存在`thread_struct`中的`thread`字段
