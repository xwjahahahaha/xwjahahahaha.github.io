---
title: 5-Cache与内存:程序放在哪儿？
tags:
  - null
categories:
  - technical
  - null
toc: true
declare: true
date: 2022-10-27 11:10:36
---

[TOC]


<!-- more -->

> 参考：
>
> * 极客时间-《操作系统45讲》
>   * 购买地址： https://time.geekbang.org/column/intro/100078401 
>   * 作者：LMOS

# Cache与内存: 程序放在哪儿？

在前面的课程里，我们已经知道了 CPU 是如何执行程序的，也研究了程序的地址空间，这里我们终于到了程序的存放地点——内存。

你知道什么是 Cache 吗？在你心中，真实的内存又是什么样子呢？今天我们就来重新认识一下 Cache 和内存，这对我们利用 Cache 写出高性能的程序代码和实现操作系统管理内存，有着巨大的帮助

通过这节课的内容，我们一起来看看内存到底是啥，它有什么特性。有了这个认识，你就能更加深入地理解我们看似熟悉的**局部性原理**，从而搞清楚，为啥 **Cache 是解决内存瓶颈的神来之笔**。最后，我还会带你分析 x86 平台上的 Cache，规避 Cache 引发的一致性问题，并让你掌握获取内存视图的方法。

那话不多说，带着刚才的问题，我们正式进入今天的学习吧！

## 从一段“经典”代码看局部性原理

不知道，你还记不记得 C 语言打印九九乘法表的代码，想不起来也没关系，下面我把它贴出来，代码很短，也很简单，就算你自己写一个也用不了一分钟，如下所示。

```c
#include <stdio.h>
int main(){
    int i,j;
    for(i=1;i<=9;i++){        
        for(j=1;j<=i;j++){
            printf("%d*%d=%2d  ",i,j,i*j);
        }
        printf("\n");
    }
    return 0;
}
```

我们当然不是为了研究代码本身，这个代码非常简单，这里我们主要是观察这个结构，代码的结构主要是**顺序、分支、循环**，这三种结构可以写出现存所有算法的程序。

我们常规情况下写的代码是顺序和循环结构居多。上面的代码中有两重循环，内层循环的次数受到外层循环变量的影响。就是这么简单，但是越简单的东西越容易看到本质。

可以看到，这个代码大数时间在执行一个乘法计算和调用一个 printf 函数，而程序一旦编译装载进内存中，它的地址就确定了。也就是说，**CPU 大多数时间在访问相同或者与此相邻的地址**，换句话说就是：CPU 大多数时间在执行相同的指令或者与此相邻的指令。这就是大名鼎鼎的**程序局部性原理**

## 内存

明白了程序的局部性原理之后，我们再来看看内存。你或许感觉这跨越有点大，但是只有明白了内存的结构和特性，你才能明白程序局部性原理的应用场景和它的重要性

内存也可称为主存，不管硬盘多大、里面存放了多少程序和数据，只要程序运行或者数据要进行计算处理，就必须先将它们装入内存。我们先来看看内存长什么样（你也可以上网自行搜索），如下图所示:

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20221130183950725.png" alt="image-20221130183950725" style="zoom:50%;" />

从上图可以看到在 PCB 板上有内存颗粒芯片，主要是用来存放数据的。SPD 芯片用于存放内存自身的容量、频率、厂商等信息。还有最显眼的金手指，用于连接数据总线和地址总线，电源等。

其实从专业角度讲，内存应该叫 **DRAM**，即**动态随机存储器**。内存储存颗粒芯片中的存储单元是由电容和相关元件做成的，电容存储电荷的多、少代表数字信号 0 和 1。

而随着时间的流逝，电容存在漏电现象，这导致电荷不足，就会让存储单元的数据出错，所以 **DRAM 需要周期性刷新**，以保持电荷状态。DRAM 结构较简单且集成度很高，通常用于制造内存条中的储存颗粒芯片。

虽然内存技术标准不断更新，但是储存颗粒的内部结构没有本质改变，还是电容存放电荷，标准看似更多，实际上只是提升了位宽、工作频率，以及传输时预取的数据位数。

比如 DDR SDRAM，即双倍速率同步动态随机存储器，它使用 2.5V 的工作电压，数据位宽为 64 位，核心频率最高为 166MHz。下面简称 DDR 内存，它表示每一个时钟脉冲传输两次数据，分别在时钟脉冲的上升沿和下降沿各传输一次数据，因此称为双倍速率的 SDRAM。

后来的 DDR2、DDR3、DDR4 也都在核心频率和预取位数上做了提升。最新的 DDR4 采用 1.2V 工作电压，数据位宽为 64 位，预取 16 位数据。DDR4 取消了双通道机制，一条内存即为一条通道，工作频率最高可达 4266MHz，单根 DDR4 内存的数据传输带宽最高为 34GB/s。

其实我们无需过多关注内存硬件层面的技术规格标准，重点需要关注的是，**内存的速度还有逻辑上内存和系统的连接方式和结构**，这样你就能意识到内存有多慢，还有是什么原因导致内存慢的。

我们还是画幅图说明吧，如下图所示:

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20221130184448864.png" alt="image-20221130184448864" style="zoom:50%;" />

结合图片我们看到，**控制内存刷新和内存读写的是内存控制器，而内存控制器集成在北桥芯片中**。传统方式下，北桥芯片存在于系统主板上，而现在由于芯片制造工艺的升级，芯片集成度越来越高，所以北桥芯片被就集成到 CPU 芯片中了，同时这也大大提升了 CPU 访问内存的性能。

而作为软件开发人员，从逻辑上我们只需要把内存看成一个巨大的字节数组就可以，而内存地址就是这个数组的下标。

## CPU 到内存的性能瓶颈

尽管 CPU 和内存是同时代发展的，但 CPU 所使用技术工艺的材料和内存是不同的，侧重点也不同，价格也不同。如果内存使用 CPU 的工艺和材料制造，那内存条的昂贵程度会超乎想象，没有多少人能买得起。

由于这些不同，导致了 CPU 和内存条的数据吞吐量天差地别。尽管最新的 DDR4 内存条带宽高达 34GB/s，然而这相比 CPU 的数据吞吐量要慢上几个数量级。再加上多核心 CPU 同时访问内存，会导致总线争用问题，数据吞吐量会进一步下降。

CPU 要数据，内存一时给不了怎么办？CPU 就得等，通常 CPU 会让总线插入等待时钟周期，直到内存准备好，到这里你就会发现，无论 CPU 的性能多高都没用，而**内存才是决定系统整体性能的关键**。显然依靠目前的理论直接提升内存性能，达到 CPU 的同等水平，这是不可行的，得想其它的办法

## Cache

让我们重新回到前面的场景中，回到程序的局部性原理，它告诉我们：CPU 大多数时间在访问相同或者与此相邻的地址。那么，我们立马就可以想到用一块**小而快**的储存器，放在 CPU 和内存之间，就可以利用程序的局部性原理来缓解 CPU 和内存之间的性能瓶颈。这块**小而快**的储存器就是 Cache，即**高速缓存**。

Cache 中存放了内存中的一部分数据，CPU 在访问内存时要先访问 Cache，若 Cache 中有需要的数据就直接从 Cache 中取出，若没有则需要从内存中读取数据，并同时把这块数据放入 Cache 中。但是由于程序的局部性原理，在一段时间内，CPU 总是能从 Cache 中读取到自己想要的数据。

Cache 可以集成在 CPU 内部，也可以做成独立的芯片放在总线上，现在 x86 CPU 和 ARM CPU 都是集成在 CPU 内部的。其逻辑结构如下图所示:

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20221130190515261.png" alt="image-20221130190515261" style="zoom:50%;" />

Cache 主要由高速的静态储存器、地址转换模块和 Cache 行替换模块组成。

Cache 会把自己的高速静态储存器和内存分成大小相同的行，一行大小通常为 32 字节或者 64 字节。Cache 和内存交换数据的最小单位是一行，为方便管理，在 Cache 内部的高速储存器中，多个行又会形成一组。

除了正常的数据空间外，Cache 行中还有一些标志位，如脏位、回写位，访问位等，这些位会被 Cache 的替换模块所使用。

Cache 大致的逻辑工作流程如下。

1.CPU 发出的地址由 Cache 的地址转换模块分成 3 段：组号，行号，行内偏移。

2.Cache 会根据组号、行号查找高速静态储存器中对应的行。如果找到即命中，用行内偏移读取并返回数据给 CPU，否则就分配一个新行并访问内存，把内存中对应的数据加载到 Cache 行并返回给 CPU。写入操作则比较直接，分为回写和直通写，回写是写入对应的 Cache 行就结束了，直通写则是在写入 Cache 行的同时写入内存。

\3. 如果没有新行了，就要进入行替换逻辑，即找出一个 Cache 行写回内存，腾出空间，替换行有相关的算法，**替换算法是为了让替换的代价最小化**。例如，找出一个没有修改的 Cache 行，这样就不用把它其中的数据回写到内存中了，还有找出存在时间最久远的那个 Cache 行，因为它大概率不会再访问了。

以上这些逻辑都由 Cache 硬件独立实现，软件不用做任何工作，对软件是透明的。
