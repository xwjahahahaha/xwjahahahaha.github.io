---
title: 8.消息、延迟、定时队列
tags:
  - null
categories:
  - technical
  - null
toc: true
declare: true
date: 2022-05-01 15:53:56
---

# 八、消息、延迟、定时队列

本项目地址 :  https://github.com/Mikaelemmmm/go-zero-looklook

## 1、概述

消息队列有很多种，有`rabbitmq`、`rocketmq`、`kafka`等常用的，其中`go-queue`(https://github.com/zeromicro/go-queue)是go-zero官方开发的消息队列组件，其中分为2类，**一种是kq、一种是dq，kq是基于kafka的消息队列，dq是基于beanstalkd的延迟队列**，但是go-queue不支持定时任务。具体想更多了解go-queue的我之前也写过一篇教程可以去看一下这里不细说了。

本项目采用的是`go-queue`做消息队列，`asynq`做延迟队列、定时队列

为什么使用`asynq`的几个原因:

- 直接基于`redis`，一般项目都有`redis`，而`asynq`本身就是基于`redis`所以可以少维护一个中间件
- 支持消息队列、延迟队列、定时任务调度 ， 因为希望项目支持定时任务而`asynq`直接就支持
- 有`webui`界面，每个任务都可以暂停、归档、通过`ui`界面查看成功失败、监控

为什么`asynq`支持消息队列还在使用`go-queue`？

- `kafka`的吞吐是业界出名的，如果前期量不大可以直接用`asynq`
- 没啥目的，就是想给你们演示一下`go-queue`

<!-- more -->

在我们使用go-zero的时候，`goctl`给我们带了很大的便利，但是目前`go-zero`只有生成`api`、`rpc`，很多同学在群里问定时任务、延迟队列、消息队列如何生成，目录结构该怎样做，其实`go-zero`是为我们设计好了的，就是`serviceGroup`，使用`serviceGroup`管理你的服务。

## 2、如何使用

在前面订单、消息等场景我们其实已经演示过了，这里在额外单独补充一次

以`go-queue`消息队列为例, 我们还是拿`order-mq`来举例子，显然使用`goctl`生成`api`、`rpc`不是我们想要的，那我们就自己使用`serviceGroup`改造，目录结构还是延续`api`的基本差不多,只是将`handler`改成了`listen` ， 将`logic`换成了`mqs` 。

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501164923038.png" alt="image-20220501164923038" style="zoom:50%;" />

业务逻辑图：

<img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501165145281.png" alt="image-20220501165145281" style="zoom: 67%;" />

### 2.1 在main中代码如下

`app/order/cmd/mq/order.go`

```go
var configFile = flag.String("f", "etc/order.yaml", "Specify the config file")

func main() {
	flag.Parse()
	var c config.Config

	conf.MustLoad(*configFile, &c)
  
	// log、prometheus、trace、metricsUrl.
  // SetUp设置服务
	if err := c.SetUp(); err != nil {
		panic(err)
	}

	serviceGroup := service.NewServiceGroup()
	defer serviceGroup.Stop()

	for _, mq := range listen.Mqs(c) {
		serviceGroup.Add(mq)
	}

	serviceGroup.Start()
}

```

- 首先我们要定义配置以及解析配置。

- 其次为什么我们要在这里加`SetUp`而`api`、`rpc`不需要呢？因为`api`、`rpc`都是在`MustNewServer`中已经框架写的，但是我们用`serviceGroup`管理没有,可以手动点进去`SetUp`看看，这个方法中包含了`log`、`prometheus`、`trace`、`metricsUrl`的定义，一个方法可以省很多事情，这样我们**直接修改配置文件就可以实现日志、监控、链路追踪**了。

  <img src="http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501165637359.png" alt="image-20220501165637359" style="zoom: 33%;" />

  ```go
  // SetUp sets up the service.
  func (sc ServiceConf) SetUp() error {
  	if len(sc.Log.ServiceName) == 0 {
  		sc.Log.ServiceName = sc.Name
  	}
  	if err := logx.SetUp(sc.Log); err != nil {
  		return err
  	}
  
  	sc.initMode()
  	prometheus.StartAgent(sc.Prometheus)
  
  	if len(sc.Telemetry.Name) == 0 {
  		sc.Telemetry.Name = sc.Name
  	}
  	trace.StartAgent(sc.Telemetry)
  
  	if len(sc.MetricsUrl) > 0 {
  		stat.SetReportWriter(stat.NewRemoteWriter(sc.MetricsUrl))
  	}
  
  	return nil
  }
  ```

- 接下来就是`go-zero`的`serivceGroup`管理服务了，`serviceGroup`是用来管理一组`service`的，那`service`其实就是一个接口，代码如下

  `Service` (代码在`go-zero/core/service/servicegroup.go`)

  ```golang
  // Service is the interface that groups Start and Stop methods.
  Service interface {
    Starter //Start
    Stopper //Stop
  }
  ```

  所以，<font color='#e54d42'>只要你的服务实现了这2个接口，就可以加入到`serviceGroup`统一管理</font>

  那可以看到我们把所有的`mq`都实现这个接口，然后统一放到都 `list.Mqs`中，在启动服务即可

### 2.2 mq分类管理

`go-zero-looklook/app/order/cmd/mq/internal/listen`目录下代码

该目录下代码是统一管理不同类型`mq`，因为我们要管理`kq`、`asynq`可能后续还有`rabbitmq`、`rocketmq`等等，所以在这里做了分类方便维护

统一管理在`go-zero-looklook/app/order/cmd/mq/internal/listen/listen.go`,然后在`main`中调用`listen.Mqs`可以获取所有`mq`一起`start`

```go
//返回所有消费者
func Mqs(c config.Config) []service.Service {

	svcContext := svc.NewServiceContext(c)
	ctx := context.Background()

	var services []service.Service

	//kq ：消息队列.
	services = append(services, KqMqs(c, ctx, svcContext)...)
	//asynq ： 延迟队列、定时任务
	services = append(services, AsynqMqs(c, ctx, svcContext)...)
	//other mq ....

	return services
}
```

`go-zero-looklook/app/order/cmd/mq/internal/listen/asynqMqs.go`就是定义的`asynq`

```go
//asynq
//定时任务、延迟任务
func AsynqMqs(c config.Config, ctx context.Context, svcContext *svc.ServiceContext) []service.Service {

   return []service.Service{
      //监听延迟队列
      deferMq.NewAsynqTask(ctx, svcContext),

      //监听定时任务
   }

}
```

`go-zero-looklook/app/order/cmd/mq/internal/listen/kqMqs.go`就是定义的`kq` (`go-queue`的`kafka`)

```go
//kq
//消息队列
func KqMqs(c config.Config, ctx context.Context, svcContext *svc.ServiceContext) []service.Service {

	return []service.Service{
		//监听消费流水状态变更
		kq.MustNewQueue(c.PaymentUpdateStatusConf, kqMq.NewPaymentUpdateStatusMq(ctx, svcContext)),
		//.....
	}

}
```

### 2.3 实际业务

编写实际业务，我们就在`go-zero-looklook/app/order/cmd/mq/internal/listen/mqs`下，这里为了方便维护，也是做了分类

- `deferMq` : 延迟队列
- `kq`：消息队列

#### 2.3.1 asynq延迟队列

```go
/**
监听关闭订单
*/
type AsynqTask struct {
   ctx    context.Context
   svcCtx *svc.ServiceContext
}

func NewAsynqTask(ctx context.Context, svcCtx *svc.ServiceContext) *AsynqTask {
   return &AsynqTask{
      ctx:    ctx,
      svcCtx: svcCtx,
   }
}

func (l *AsynqTask) Start() {

   fmt.Println("AsynqTask start ")

   srv := asynq.NewServer(
      asynq.RedisClientOpt{Addr: l.svcCtx.Config.Redis.Host, Password: l.svcCtx.Config.Redis.Pass},
      asynq.Config{
         Concurrency: 10,
         Queues: map[string]int{
            "critical": 6,
            "default":  3,
            "low":      1,
         },
      },
   )

   mux := asynq.NewServeMux()

   //关闭民宿订单任务
   mux.HandleFunc(asynqmq.TypeHomestayOrderCloseDelivery, l.closeHomestayOrderStateMqHandler)

   if err := srv.Run(mux); err != nil {
      log.Fatalf("could not run server: %v", err)
   }
}

func (l *AsynqTask) Stop() {
   fmt.Println("AsynqTask stop")
}
```

因为`asynq` 要先启动，然后定义路由任务，所以我们在`asynqTask.go`中做了统一的路由管理，之后我们每个业务都单独的在`deferMq`的文件夹下面定义一个文件（如“延迟关闭订单：`closeHomestayOrderState.go`”),这样每个业务一个文件，跟`go-zero`的`api`、`rpc`的`logic`一样，维护很方便

`closeHomestayOrderState.go` 关闭订单逻辑

```go
package deferMq

import (
	"context"
	"encoding/json"
	"looklook/app/order/cmd/rpc/order"
	"looklook/app/order/model"
	"looklook/common/asynqmq"
	"looklook/common/xerr"

	"github.com/hibiken/asynq"
	"github.com/pkg/errors"
)

func (l *AsynqTask) closeHomestayOrderStateMqHandler(ctx context.Context, t *asynq.Task) error {

	var p asynqmq.HomestayOrderCloseTaskPayload
	if err := json.Unmarshal(t.Payload(), &p); err != nil {
		return errors.Wrapf(xerr.NewErrMsg("解析asynq task payload err"), "closeHomestayOrderStateMqHandler payload err:%v, payLoad:%+v", err, t.Payload())
	}

	resp, err := l.svcCtx.OrderRpc.HomestayOrderDetail(ctx, &order.HomestayOrderDetailReq{
		Sn: p.Sn,
	})
	if err != nil || resp.HomestayOrder == nil {
		return errors.Wrapf(xerr.NewErrMsg("获取订单失败"), "closeHomestayOrderStateMqHandler 获取订单失败 or 订单不存在 err:%v, sn:%s ,HomestayOrder : %+v", err, p.Sn, resp.HomestayOrder)
	}

	if resp.HomestayOrder.TradeState == model.HomestayOrderTradeStateWaitPay {
		_, err := l.svcCtx.OrderRpc.UpdateHomestayOrderTradeState(ctx, &order.UpdateHomestayOrderTradeStateReq{
			Sn:         p.Sn,
			TradeState: model.HomestayOrderTradeStateCancel,
		})
		if err != nil {
			return errors.Wrapf(xerr.NewErrMsg("关闭订单失败"), "closeHomestayOrderStateMqHandler 关闭订单失败  err:%v, sn:%s ", err, p.Sn)
		}
	}

	return nil
}
```

#### 2.3.2 kq消息队列

看`go-zero-looklook/app/order/cmd/mq/internal/mqs/kq`文件夹下，因为`kq`跟`asynq`不太一样，它本身就是使用`go-zero`的`Service`管理的，已经实现了`starter`、`stopper`接口了，所以我们在`/Users/seven/Developer/goenv/go-zero-looklook/app/order/cmd/mq/internal/listen/kqMqs.go`中直接定义好一个`go-queue`业务扔给`serviceGroup`，去交给`main`启动就好了 , 我们的业务代码只需要实现`go-queue`的`Consumer`直接写我们自己业务即可。

1）`/Users/seven/Developer/goenv/go-zero-looklook/app/order/cmd/mq/internal/listen/kqMqs.go`

```go
func KqMqs(c config.Config, ctx context.Context, svcContext *svc.ServiceContext) []service.Service {

	return []service.Service{
		//监听消费流水状态变更
		kq.MustNewQueue(c.PaymentUpdateStatusConf, kqMq.NewPaymentUpdateStatusMq(ctx, svcContext)),
		//.....
	}
}
```

可以看到`kq.MustNewQueue`本身返回就是 `queue.MessageQueue` ， `queue.MessageQueue`又实现了`Start`、`Stop`

```go
package queue

// A MessageQueue interface represents a message queue.
type MessageQueue interface {
	Start()
	Stop()
}
```

2）业务中

`/Users/seven/Developer/goenv/go-zero-looklook/app/order/cmd/mq/internal/mqs/kq/paymentUpdateStatus.go`

```go
func (l *PaymentUpdateStatusMq) Consume(_, val string) error {
	fmt.Printf(" PaymentUpdateStatusMq Consume val : %s \n", val)
	//解析数据
	var message kqueue.ThirdPaymentUpdatePayStatusNotifyMessage
	if err := json.Unmarshal([]byte(val), &message); err != nil {
		logx.WithContext(l.ctx).Error("PaymentUpdateStatusMq->Consume Unmarshal err : %v , val : %s", err, val)
		return err
	}

	//执行业务
	if err := l.execService(message); err != nil {
		logx.WithContext(l.ctx).Error("PaymentUpdateStatusMq->execService  err : %v , val : %s , message:%+v", err, val, message)
		return err
	}

	return nil
}
```

我们在`paymentUpdateStatus.go`中只需要实现接口`Consume `就可以接受来自`kq`传过来的`kafka`的消息了，我们只管在我们`Consumer`中处理我们业务即可

## 3、定时任务

关于定时任务，目前`go-zero-looklook`没有使用，这里我也说明一下

- 如果你想简单一点直接使用`cron`（裸机、k8s都有），
- 如果稍微复杂一点可以使用https://github.com/robfig/cron包，在代码中定义时间
- 使用`xxl-job`、`gocron`分布式定时任务系统接入
- `asynq`的`shedule`

⚠️项目中具体可以看一下`app/mqueue/cmd/scheduler`与`app/mqueue/cmd/job`

这里我演示一下`asynq`的`shedule `

分为`client`与`server` ，` client`用来定义调度时间，`server`是到了时间接受`client`的消息触发来执行我们写的业务的，实际业务我们应该写在`server`，`client`用来定义业务调度时间的

`asynqtest/docker-compose.yml`

```yaml
version: '3'

services:

  #asynqmon asynq延迟队列、定时队列的webui
  asynqmon:
    image: hibiken/asynqmon:latest
    container_name: asynqmon_asynq
    ports:
      - 8980:8080
    command:
      - '--redis-addr=redis:6379'
      - '--redis-password=G62m50oigInC30sf'
    restart: always
    networks:
      - asynqtest_net
    depends_on:
      - redis
  

  #redis容器
  redis:
    image: redis:6.2.5
    container_name: redis_asynq
    ports:
      - 63779:6379
    environment:
      # 时区上海
      TZ: Asia/Shanghai
    volumes:
      # 数据文件
      - ./data/redis/data:/data:rw
    command: "redis-server --requirepass G62m50oigInC30sf  --appendonly yes"
    privileged: true
    restart: always
    networks:
      - asynqtest_net


networks:
  asynqtest_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.22.0.0/16
```

`asynqtest/shedule/client/client.go`

```go
package main

import (
	"asynqtest/tpl"
	"encoding/json"
	"log"

	"github.com/hibiken/asynq"
)

const redisAddr = "127.0.0.1:63779"
const redisPwd = "G62m50oigInC30sf"

func main() {
	// 周期性任务
	scheduler := asynq.NewScheduler(
		asynq.RedisClientOpt{
			Addr:     redisAddr,
			Password: redisPwd,
		}, nil)

	payload, err := json.Marshal(tpl.EmailPayload{Email: "546630576@qq.com", Content: "发邮件呀"})
	if err != nil {
		log.Fatal(err)
	}

	task := asynq.NewTask(tpl.EMAIL_TPL, payload)
	// 每隔1分钟同步一次
	entryID, err := scheduler.Register("*/1 * * * *", task)

	if err != nil {
		log.Fatal(err)
	}
	log.Printf("registered an entry: %q\n", entryID)

	if err := scheduler.Run(); err != nil {
		log.Fatal(err)
	}
}

```

`asynqtest/shedule/server/server.go`

```go
package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"

	"asynqtest/tpl"

	"github.com/hibiken/asynq"
)

func main() {
	srv := asynq.NewServer(
		asynq.RedisClientOpt{Addr: "127.0.0.1:63779", Password: "G62m50oigInC30sf"},
		asynq.Config{
			Concurrency: 10,
			Queues: map[string]int{
				"critical": 6,
				"default":  3,
				"low":      1,
			},
		},
	)

	mux := asynq.NewServeMux()
	
  // 处理路由
	mux.HandleFunc(tpl.EMAIL_TPL, emailMqHandler)

	if err := srv.Run(mux); err != nil {
		log.Fatalf("could not run server: %v", err)
	}
}

func emailMqHandler(ctx context.Context, t *asynq.Task) error {

	var p tpl.EmailPayload
	if err := json.Unmarshal(t.Payload(), &p); err != nil {
		return fmt.Errorf("emailMqHandler err:%+v", err)
	}

	fmt.Printf("p : %+v \n", p)

	return nil

}

```

`asynqtest/tpl/tpl.go`

```go
package tpl

const EMAIL_TPL = "schedule:email"

type EmailPayload struct {
	Email   string
	Content string
}
```

启动server.go、client.go 

![image-20220501212724554](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501212724554.png)

![image-20220501212737939](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501212737939.png)

浏览器输入http://127.0.0.1:8980/schedulers这里 可以看到所有client定义的任务

![image-20220501212839307](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501212839307.png)

浏览器输入http://127.0.0.1:8980/这里可以看到我们的server消费情况

![image-20220501213403854](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501213403854.png)

控制台消费情况

![image-20220501213428517](http://xwjpics.gumptlu.work/qinniu_uPic/image-20220501213428517.png)

说一下`asynq`的`shedule`在集成到项目中的思路，可以单独启动一个服务作为调度`client`定义系统的定时任务调度管理，将`server`定义在每个业务自己的`mq`的`asynq`一起即可。

## 4、结尾

在这一节中，我们学会使用了消息队列、延迟队列 ，kafka可以通过管理工具去查看，至于asynq查看webui在`go-zero-looklook/docker-compose-env.yml`中我们已经启动好了`asynqmon`，直接使用http://127.0.0.1:8980 即可查看













